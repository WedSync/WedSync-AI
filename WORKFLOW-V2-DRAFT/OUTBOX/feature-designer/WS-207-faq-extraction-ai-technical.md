# TECHNICAL SPECIFICATION: WS-207 - FAQ Extraction AI
## Generated by Feature Development Session - 2025-08-25

### USER STORY & BUSINESS CONTEXT (THINK HARD - BE FACTUAL)
**As a:** Wedding vendor who has a website with FAQs scattered across multiple pages
**I want to:** Automatically import all my existing FAQs into WedSync with proper categorization
**So that:** Couples can find answers instantly without me answering the same 20 questions daily, saving 5+ hours per week

**Real Wedding Scenario:**
A wedding photographer has 50+ FAQs on their website about pricing, travel fees, album options, and timeline questions. Currently, they copy-paste answers from a Word document 20+ times per week to respond to couples. With FAQ extraction, they enter their website URL once, the AI finds and extracts all FAQs, categorizes them (pricing, booking, service, logistics), and makes them instantly available to couples through the chatbot. When a couple asks "Do you charge travel fees?", they get the answer immediately instead of waiting 24 hours for an email response.

### SPECIFICATION SOURCE
- **Feature ID:** WS-207
- **Original Spec:** /CORE-SPECIFICATIONS/04-AI-INTEGRATION/03-Content-Generation/02-faq-extraction md.md
- **Current Implementation:** 0% complete
- **Files to Modify:**
  - /wedsync/src/app/api/faqs/route.ts
  - /wedsync/src/components/settings/FAQManager.tsx
- **New Files to Create:**
  - /wedsync/src/lib/ai/faq-extractor.ts
  - /wedsync/src/lib/ai/faq-categorizer.ts
  - /wedsync/src/lib/ai/wedding-faq-enhancer.ts
  - /wedsync/src/lib/scraping/website-scraper.ts
  - /wedsync/src/components/faq/FAQExtractionWizard.tsx
  - /wedsync/src/components/faq/FAQReviewQueue.tsx
  - /wedsync/src/types/faq-extraction.ts

### TECHNICAL DESIGN

#### Database Schema Required
```sql
-- Extracted FAQs storage
CREATE TABLE IF NOT EXISTS extracted_faqs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  supplier_id UUID REFERENCES suppliers(id) ON DELETE CASCADE,
  question TEXT NOT NULL,
  answer TEXT NOT NULL,
  category TEXT CHECK (category IN ('pricing', 'booking', 'service', 'logistics', 'general')),
  source_url TEXT NOT NULL,
  source_page_title TEXT,
  extraction_method TEXT DEFAULT 'ai',
  confidence_score DECIMAL(3,2) DEFAULT 0.00,
  approved BOOLEAN DEFAULT false,
  approved_by UUID REFERENCES auth.users(id),
  approved_at TIMESTAMP WITH TIME ZONE,
  edited BOOLEAN DEFAULT false,
  original_question TEXT,
  original_answer TEXT,
  extracted_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  last_verified_at TIMESTAMP WITH TIME ZONE,
  is_active BOOLEAN DEFAULT true,
  metadata JSONB DEFAULT '{}'::jsonb
);

-- FAQ extraction jobs
CREATE TABLE IF NOT EXISTS faq_extraction_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  supplier_id UUID REFERENCES suppliers(id) ON DELETE CASCADE,
  website_url TEXT NOT NULL,
  vendor_type TEXT NOT NULL,
  status TEXT CHECK (status IN ('pending', 'processing', 'completed', 'failed', 'review')),
  started_at TIMESTAMP WITH TIME ZONE,
  completed_at TIMESTAMP WITH TIME ZONE,
  total_pages_scraped INTEGER DEFAULT 0,
  total_faqs_extracted INTEGER DEFAULT 0,
  total_faqs_approved INTEGER DEFAULT 0,
  error_message TEXT,
  scraped_content TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- FAQ categories configuration
CREATE TABLE IF NOT EXISTS faq_categories (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  supplier_id UUID REFERENCES suppliers(id) ON DELETE CASCADE,
  category_name TEXT NOT NULL,
  category_keywords TEXT[],
  display_order INTEGER DEFAULT 0,
  icon TEXT,
  color TEXT,
  is_default BOOLEAN DEFAULT false,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  UNIQUE(supplier_id, category_name)
);

-- FAQ usage analytics
CREATE TABLE IF NOT EXISTS faq_analytics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  faq_id UUID REFERENCES extracted_faqs(id) ON DELETE CASCADE,
  viewed_by TEXT, -- Email or user ID
  viewed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  helpful_rating INTEGER CHECK (helpful_rating BETWEEN 1 AND 5),
  search_query TEXT,
  click_position INTEGER,
  session_id TEXT
);

-- Website scraping cache
CREATE TABLE IF NOT EXISTS website_scrape_cache (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  url TEXT NOT NULL UNIQUE,
  content TEXT NOT NULL,
  page_title TEXT,
  meta_description TEXT,
  scraped_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  expires_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() + INTERVAL '30 days',
  robots_txt_compliant BOOLEAN DEFAULT true,
  scrape_duration_ms INTEGER
);

-- Indexes
CREATE INDEX idx_extracted_faqs_supplier ON extracted_faqs(supplier_id);
CREATE INDEX idx_extracted_faqs_category ON extracted_faqs(category);
CREATE INDEX idx_extracted_faqs_approved ON extracted_faqs(approved);
CREATE INDEX idx_extraction_jobs_supplier ON faq_extraction_jobs(supplier_id);
CREATE INDEX idx_faq_analytics_faq ON faq_analytics(faq_id);
CREATE INDEX idx_scrape_cache_url ON website_scrape_cache(url);
CREATE INDEX idx_scrape_cache_expires ON website_scrape_cache(expires_at);
```

#### API Endpoints Required
```typescript
// POST /api/faqs/extract
interface ExtractFAQsRequest {
  websiteUrl: string;
  vendorType: 'photographer' | 'dj' | 'caterer' | 'venue' | 'florist' | 'planner';
  specificPages?: string[]; // Optional specific pages to scrape
  enhanceForWeddings?: boolean; // Add wedding context
}

interface ExtractFAQsResponse {
  success: boolean;
  jobId: string;
  estimatedTime: number; // seconds
  message: string;
}

// GET /api/faqs/extraction-job/:jobId
interface GetExtractionJobResponse {
  jobId: string;
  status: 'pending' | 'processing' | 'completed' | 'failed' | 'review';
  progress: number; // 0-100
  totalPagesScraped: number;
  totalFAQsExtracted: number;
  extractedFAQs?: {
    id: string;
    question: string;
    answer: string;
    category: string;
    confidence: number;
  }[];
  error?: string;
}

// POST /api/faqs/:id/review
interface ReviewFAQRequest {
  approved: boolean;
  edits?: {
    question?: string;
    answer?: string;
    category?: string;
  };
}

interface ReviewFAQResponse {
  success: boolean;
  faq: ExtractedFAQ;
}

// POST /api/faqs/bulk-approve
interface BulkApproveFAQsRequest {
  faqIds: string[];
  action: 'approve' | 'reject' | 'edit';
  edits?: Record<string, Partial<FAQ>>;
}

interface BulkApproveFAQsResponse {
  success: boolean;
  approved: number;
  rejected: number;
  edited: number;
}

// POST /api/faqs/categorize
interface CategorizeFAQsRequest {
  faqs: { question: string; answer: string }[];
  customCategories?: string[];
}

interface CategorizeFAQsResponse {
  categorizedFAQs: {
    question: string;
    answer: string;
    category: string;
    confidence: number;
  }[];
}
```

#### Frontend Components Required
```typescript
// Component: FAQExtractionWizard
// Location: /src/components/faq/FAQExtractionWizard.tsx

interface FAQExtractionWizardProps {
  vendorType: string;
  onComplete: (faqs: ExtractedFAQ[]) => void;
}

// Key functionality:
- Step 1: Enter website URL
- Step 2: Select pages to scrape
- Step 3: Processing with progress
- Step 4: Review extracted FAQs
- Step 5: Approve/edit FAQs
- Step 6: Categorization review

// Component: FAQReviewQueue
// Location: /src/components/faq/FAQReviewQueue.tsx

interface FAQReviewQueueProps {
  extractedFAQs: ExtractedFAQ[];
  onApprove: (faq: ExtractedFAQ) => void;
  onReject: (faq: ExtractedFAQ) => void;
  onEdit: (faq: ExtractedFAQ, edits: Partial<FAQ>) => void;
}

// Key functionality:
- Card view of extracted FAQs
- Confidence score display
- Quick approve/reject buttons
- Inline editing capability
- Bulk selection and actions
- Category assignment

// Component: FAQCategoryManager
// Location: /src/components/faq/FAQCategoryManager.tsx

interface FAQCategoryManagerProps {
  categories: FAQCategory[];
  onAddCategory: (category: FAQCategory) => void;
  onEditKeywords: (categoryId: string, keywords: string[]) => void;
}

// Key functionality:
- Manage FAQ categories
- Define keywords for auto-categorization
- Set display order
- Choose icons and colors
```

#### Integration Points
```typescript
// Service: WebsiteScraper
// Dependencies: Playwright, robots-txt parser, cache service

class WebsiteScraper {
  private browser: Browser | null = null;
  
  async scrapeWebsite(url: string, options?: ScrapeOptions): Promise<ScrapedContent> {
    // Check robots.txt compliance
    // Check cache first
    // Launch headless browser
    // Navigate and extract content
    // Store in cache
  }
  
  async findFAQPages(baseUrl: string): Promise<string[]> {
    // Crawl site for FAQ pages
    // Look for FAQ patterns in URLs and content
    // Return list of FAQ page URLs
  }
  
  private async respectRobotsTxt(url: string): Promise<boolean> {
    // Parse robots.txt
    // Check if scraping allowed
    // Respect crawl delay
  }
}

// Service: FAQExtractor
// Dependencies: OpenAI API, scraper, categorizer

class FAQExtractor {
  async extractFAQs(content: string, vendorType: string): Promise<ExtractedFAQ[]> {
    // Use AI to extract Q&A pairs
    // Parse various FAQ formats
    // Clean and structure data
    // Calculate confidence scores
  }
  
  async enhanceForWeddings(faqs: FAQ[], vendorType: string): Promise<FAQ[]> {
    // Add wedding-specific context
    // Improve question clarity
    // Enhance answers with wedding relevance
  }
}

// Service: FAQCategorizer
class FAQCategorizer {
  async categorize(faqs: FAQ[]): Promise<CategorizedFAQ[]> {
    // Apply keyword matching
    // Use AI for ambiguous cases
    // Return categorized FAQs
  }
}
```

### CODE EXAMPLES

#### Example 1: Website Scraping with Playwright
```typescript
// ACTUAL CODE PATTERN TO FOLLOW:
import { chromium, Browser, Page } from 'playwright';
import robotsParser from 'robots-txt-parser';
import { supabase } from '@/lib/supabase';

export class WebsiteScraper {
  private browser: Browser | null = null;
  private robotsCache: Map<string, any> = new Map();
  
  async scrapeWebsite(url: string, vendorType: string): Promise<ScrapedContent> {
    // Step 1: Check robots.txt compliance
    const isAllowed = await this.checkRobotsTxt(url);
    if (!isAllowed) {
      throw new Error('Scraping not allowed by robots.txt');
    }
    
    // Step 2: Check cache
    const cached = await this.checkCache(url);
    if (cached) {
      return cached;
    }
    
    // Step 3: Launch browser and scrape
    try {
      this.browser = await chromium.launch({ 
        headless: true,
        args: ['--no-sandbox', '--disable-setuid-sandbox']
      });
      
      const page = await this.browser.newPage();
      await page.setUserAgent('WedSync FAQ Bot 1.0 (compatible; +https://wedsync.com/bot)');
      
      // Navigate with timeout
      await page.goto(url, { 
        waitUntil: 'networkidle',
        timeout: 30000 
      });
      
      // Step 4: Find FAQ content using multiple strategies
      const faqContent = await this.extractFAQContent(page);
      
      // Step 5: Find additional FAQ pages
      const faqPages = await this.findFAQPages(page, url);
      
      // Step 6: Scrape additional pages
      const allContent: string[] = [faqContent];
      for (const faqPage of faqPages.slice(0, 5)) { // Limit to 5 pages
        await page.goto(faqPage, { waitUntil: 'networkidle' });
        const pageContent = await this.extractFAQContent(page);
        allContent.push(pageContent);
        
        // Rate limiting
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
      
      // Step 7: Cache the content
      const scrapedContent = {
        url,
        content: allContent.join('\n\n'),
        pageTitle: await page.title(),
        metaDescription: await page.$eval(
          'meta[name="description"]',
          el => el.getAttribute('content')
        ).catch(() => ''),
        scrapedAt: new Date()
      };
      
      await this.cacheContent(url, scrapedContent);
      
      return scrapedContent;
      
    } finally {
      if (this.browser) {
        await this.browser.close();
      }
    }
  }
  
  private async extractFAQContent(page: Page): Promise<string> {
    // Multiple strategies to find FAQ content
    const strategies = [
      // Strategy 1: Look for FAQ-specific selectors
      async () => {
        const selectors = [
          '[class*="faq"]',
          '[id*="faq"]',
          '[data-faq]',
          '.accordion',
          '[itemtype*="FAQPage"]',
          'h2:has-text("FAQ")',
          'h2:has-text("Frequently Asked")',
          'h3:has-text("Questions")'
        ];
        
        let content = '';
        for (const selector of selectors) {
          const elements = await page.$$(selector);
          for (const element of elements) {
            const parent = await element.evaluateHandle(el => el.parentElement);
            content += await parent.evaluate(el => el?.textContent || '') + '\n';
          }
        }
        return content;
      },
      
      // Strategy 2: Look for Q&A patterns
      async () => {
        return await page.evaluate(() => {
          const patterns = [
            /Q:\s*.+?\s*A:\s*.+?/gs,
            /Question:\s*.+?\s*Answer:\s*.+?/gs,
            /<dt>.+?<\/dt>\s*<dd>.+?<\/dd>/gs
          ];
          
          let content = '';
          const bodyText = document.body.innerText;
          
          for (const pattern of patterns) {
            const matches = bodyText.match(pattern);
            if (matches) {
              content += matches.join('\n');
            }
          }
          
          return content;
        });
      },
      
      // Strategy 3: Structured data
      async () => {
        return await page.evaluate(() => {
          const scripts = Array.from(document.querySelectorAll('script[type="application/ld+json"]'));
          let faqs = '';
          
          for (const script of scripts) {
            try {
              const data = JSON.parse(script.textContent || '');
              if (data['@type'] === 'FAQPage' && data.mainEntity) {
                for (const item of data.mainEntity) {
                  faqs += `Q: ${item.name}\nA: ${item.acceptedAnswer?.text}\n\n`;
                }
              }
            } catch {}
          }
          
          return faqs;
        });
      }
    ];
    
    // Try all strategies and combine results
    const results = await Promise.all(strategies.map(s => s().catch(() => '')));
    return results.filter(r => r).join('\n\n');
  }
  
  private async checkRobotsTxt(url: string): Promise<boolean> {
    const origin = new URL(url).origin;
    
    if (this.robotsCache.has(origin)) {
      return this.robotsCache.get(origin);
    }
    
    try {
      const robotsUrl = `${origin}/robots.txt`;
      const response = await fetch(robotsUrl);
      
      if (!response.ok) {
        // No robots.txt means allowed
        this.robotsCache.set(origin, true);
        return true;
      }
      
      const robotsTxt = await response.text();
      const robots = robotsParser(robotsUrl, robotsTxt);
      
      const isAllowed = robots.isAllowed(url, 'WedSync FAQ Bot');
      this.robotsCache.set(origin, isAllowed);
      
      return isAllowed;
    } catch {
      // Error fetching robots.txt - assume allowed
      return true;
    }
  }
}
```

#### Example 2: AI FAQ Extraction
```typescript
// ACTUAL CODE PATTERN TO FOLLOW:
import { OpenAI } from 'openai';

export class FAQExtractor {
  private openai: OpenAI;
  
  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
  }
  
  async extractFAQs(content: string, vendorType: string): Promise<ExtractedFAQ[]> {
    // Step 1: Build extraction prompt
    const systemPrompt = `You are an expert at extracting FAQ information from wedding vendor websites.
    Extract question and answer pairs from the provided content.
    Focus on ${vendorType}-specific questions.
    Return valid JSON array of objects with 'question' and 'answer' fields.`;
    
    const userPrompt = `Extract all FAQ question and answer pairs from this content:
    
    ${content.substring(0, 10000)} // Limit to 10k chars for API
    
    Return as JSON array with this structure:
    [
      {
        "question": "The question text",
        "answer": "The complete answer text",
        "confidence": 0.95
      }
    ]`;
    
    // Step 2: Call OpenAI API
    const response = await this.openai.chat.completions.create({
      model: 'gpt-3.5-turbo-1106', // JSON mode supported
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      response_format: { type: 'json_object' },
      temperature: 0.3, // Lower temperature for accuracy
      max_tokens: 2000
    });
    
    // Step 3: Parse and validate response
    try {
      const parsed = JSON.parse(response.choices[0].message.content || '{"faqs": []}');
      const faqs = parsed.faqs || parsed; // Handle different response structures
      
      // Step 4: Enhance with wedding context if needed
      const enhanced = await this.enhanceForWeddings(faqs, vendorType);
      
      // Step 5: Calculate confidence scores
      return enhanced.map(faq => ({
        ...faq,
        confidence: this.calculateConfidence(faq)
      }));
      
    } catch (error) {
      console.error('Failed to parse FAQ extraction:', error);
      return [];
    }
  }
  
  async enhanceForWeddings(faqs: any[], vendorType: string): Promise<any[]> {
    const weddingKeywords = ['wedding', 'ceremony', 'reception', 'bride', 'groom', 'couple'];
    
    return faqs.map(faq => {
      // Check if already has wedding context
      const hasWeddingContext = weddingKeywords.some(keyword => 
        faq.question.toLowerCase().includes(keyword) ||
        faq.answer.toLowerCase().includes(keyword)
      );
      
      if (!hasWeddingContext) {
        // Add wedding context based on vendor type
        const contexts: Record<string, string> = {
          photographer: ' for my wedding',
          dj: ' for my wedding reception',
          caterer: ' for my wedding catering',
          venue: ' for hosting my wedding',
          florist: ' for my wedding flowers',
          planner: ' for planning my wedding'
        };
        
        const context = contexts[vendorType] || ' for my wedding';
        
        // Add context to question if it makes sense
        if (!faq.question.endsWith('?')) {
          faq.question += '?';
        }
        
        faq.question = faq.question.replace('?', `${context}?`);
      }
      
      return faq;
    });
  }
  
  private calculateConfidence(faq: any): number {
    let confidence = 0.5; // Base confidence
    
    // Increase confidence based on quality indicators
    if (faq.question && faq.answer) {
      confidence += 0.2;
    }
    
    if (faq.question.endsWith('?')) {
      confidence += 0.1;
    }
    
    if (faq.answer.length > 20) {
      confidence += 0.1;
    }
    
    if (faq.answer.length > 100) {
      confidence += 0.1;
    }
    
    return Math.min(confidence, 1.0);
  }
}
```

#### Example 3: FAQ Categorization
```typescript
// ACTUAL CODE PATTERN TO FOLLOW:
export class FAQCategorizer {
  private categories = {
    pricing: {
      keywords: ['price', 'cost', 'fee', 'payment', 'deposit', 'budget', 'package', 'rate'],
      patterns: [/how much/i, /what.*cost/i, /pricing/i]
    },
    booking: {
      keywords: ['book', 'available', 'schedule', 'date', 'reserve', 'calendar', 'availability'],
      patterns: [/how.*book/i, /when.*available/i, /schedule/i]
    },
    service: {
      keywords: ['include', 'provide', 'offer', 'deliver', 'service', 'what you do'],
      patterns: [/what.*include/i, /do you provide/i, /services/i]
    },
    logistics: {
      keywords: ['time', 'location', 'travel', 'setup', 'arrival', 'duration', 'where'],
      patterns: [/how long/i, /where.*located/i, /travel/i]
    },
    general: {
      keywords: [],
      patterns: []
    }
  };
  
  async categorizeFAQs(faqs: FAQ[]): Promise<CategorizedFAQ[]> {
    return faqs.map(faq => {
      const category = this.determineCategory(faq);
      
      return {
        ...faq,
        category,
        categoryConfidence: this.calculateCategoryConfidence(faq, category)
      };
    });
  }
  
  private determineCategory(faq: FAQ): string {
    const text = `${faq.question} ${faq.answer}`.toLowerCase();
    const scores: Record<string, number> = {};
    
    // Calculate scores for each category
    for (const [category, config] of Object.entries(this.categories)) {
      if (category === 'general') continue;
      
      let score = 0;
      
      // Check keywords
      for (const keyword of config.keywords) {
        if (text.includes(keyword)) {
          score += 1;
        }
      }
      
      // Check patterns
      for (const pattern of config.patterns) {
        if (pattern.test(text)) {
          score += 2; // Patterns are more specific
        }
      }
      
      scores[category] = score;
    }
    
    // Find highest scoring category
    let maxScore = 0;
    let selectedCategory = 'general';
    
    for (const [category, score] of Object.entries(scores)) {
      if (score > maxScore) {
        maxScore = score;
        selectedCategory = category;
      }
    }
    
    return selectedCategory;
  }
  
  private calculateCategoryConfidence(faq: FAQ, category: string): number {
    if (category === 'general') return 0.5;
    
    const text = `${faq.question} ${faq.answer}`.toLowerCase();
    const config = this.categories[category];
    
    let matches = 0;
    let totalChecks = config.keywords.length + config.patterns.length;
    
    for (const keyword of config.keywords) {
      if (text.includes(keyword)) matches++;
    }
    
    for (const pattern of config.patterns) {
      if (pattern.test(text)) matches++;
    }
    
    return totalChecks > 0 ? matches / totalChecks : 0;
  }
}
```

### MCP SERVER USAGE

#### Required MCP Servers
- [x] Context7: Load docs for Playwright, OpenAI API
- [x] Playwright: Scrape websites, test extraction
- [x] Filesystem: Access scraper and AI service files
- [ ] OpenAI MCP: Extract FAQs from content (when available)

#### Context7 Queries Needed
```typescript
await mcp__context7__get-library-docs("/playwright/playwright", "web scraping", 3000);
await mcp__context7__get-library-docs("/openai/openai", "json mode", 2000);
await mcp__context7__get-library-docs("/robots-txt-parser/robots-txt-parser", "compliance", 2000);
```

### TEST REQUIREMENTS

#### Unit Tests Required
```typescript
describe('FAQExtractor', () => {
  it('should extract Q&A pairs from various formats', () => {
    const content = `
      Q: What are your prices?
      A: Our packages start at $2000.
      
      Question: Do you travel?
      Answer: Yes, we travel worldwide.
    `;
    
    const faqs = extractor.extractFAQs(content);
    expect(faqs).toHaveLength(2);
    expect(faqs[0].question).toContain('prices');
    expect(faqs[1].answer).toContain('travel worldwide');
  });
  
  it('should categorize FAQs correctly', () => {
    const faq = {
      question: 'What is your pricing?',
      answer: 'Packages start at $1500'
    };
    
    const categorized = categorizer.categorize([faq]);
    expect(categorized[0].category).toBe('pricing');
  });
  
  it('should respect robots.txt', async () => {
    // Mock robots.txt that disallows scraping
    const allowed = await scraper.checkRobotsTxt('https://example.com/private');
    expect(allowed).toBe(false);
  });
});
```

#### E2E Tests Required
```typescript
// Using Playwright MCP
test('Extract FAQs from website', async () => {
  await mcp__playwright__browser_navigate({url: '/settings/faqs'});
  
  // Start extraction wizard
  await mcp__playwright__browser_click({
    element: 'Extract from Website button',
    ref: 'extract-website-btn'
  });
  
  // Enter website URL
  await mcp__playwright__browser_type({
    element: 'Website URL input',
    ref: 'website-url-input',
    text: 'https://example-wedding-photo.com'
  });
  
  // Start extraction
  await mcp__playwright__browser_click({
    element: 'Start Extraction button',
    ref: 'start-extraction-btn'
  });
  
  // Wait for processing
  await mcp__playwright__browser_wait_for({text: 'Extraction Complete'});
  
  // Verify FAQs extracted
  await mcp__playwright__browser_snapshot();
  
  // Approve an FAQ
  await mcp__playwright__browser_click({
    element: 'Approve button for first FAQ',
    ref: 'approve-faq-0'
  });
});
```

### ACCEPTANCE CRITERIA
- [ ] Extract FAQs from multiple page formats
- [ ] Respect robots.txt and rate limits
- [ ] Cache scraped content for 30 days
- [ ] Categorize FAQs with 80%+ accuracy
- [ ] Add wedding context to generic FAQs
- [ ] Manual review queue for all extracted FAQs
- [ ] Bulk approval/rejection capability
- [ ] Extraction completes within 60 seconds for 5 pages
- [ ] Performance: Scraping uses < 100MB memory
- [ ] Security: No execution of scraped JavaScript
- [ ] Accessibility: Review queue keyboard navigable

### DEPENDENCIES
- Must complete after: OpenAI API integration
- Must complete before: Chatbot FAQ responses
- Shares code with: WS-210 (AI Knowledge Base)

### ESTIMATED EFFORT
- Team A Frontend: 16 hours
- Team B Backend: 24 hours
- Team C Integration: 12 hours
- Team D Platform: 4 hours
- Team E General: 20 hours (AI/scraping implementation)
- Team F Workflows: 4 hours
- Team G Performance: 4 hours
- Total: 84 hours