# TECHNICAL SPECIFICATION: WS-210 - AI Knowledge Base System
## Generated by Feature Development Session - 2025-08-25

### USER STORY & BUSINESS CONTEXT (THINK HARD - BE FACTUAL)
**As a:** Wedding supplier with an AI chatbot
**I want to:** Build a structured knowledge base from my FAQs, articles, forms, and website content with intelligent search
**So that:** My chatbot provides accurate, contextual answers that reduce support tickets by 60% and improve client self-service experience

**Real Wedding Scenario:**
David runs a DJ service and gets 50+ inquiries per week about song requests, setup requirements, and timeline logistics. His current FAQ is buried on his website. An AI knowledge base would extract this information, categorize it by importance, and let his chatbot instantly answer "Do you provide wireless microphones for outdoor ceremonies?" with venue-specific context and equipment details.

### SPECIFICATION SOURCE
- **Feature ID:** WS-210
- **Original Spec:** /Users/skyphotography/CODE/WedSync-2.0/WedSync2/CORE-SPECIFICATIONS/04-AI-INTEGRATION/04-Chatbot/01-knowledge-base md.md
- **Current Implementation:** 0% complete
- **Files to Modify:**
  - `/wedsync/src/components/faq/FAQManagement.tsx` (add knowledge base integration)
- **New Files to Create:**
  - `/wedsync/src/lib/ai/knowledge-search.ts`
  - `/wedsync/src/lib/ai/content-chunker.ts`
  - `/wedsync/src/lib/ai/source-prioritizer.ts`
  - `/wedsync/src/components/ai/KnowledgeBaseManager.tsx`
  - `/wedsync/src/components/ai/ContentIndexer.tsx`
  - `/wedsync/src/app/api/chatbot/knowledge/index/route.ts`
  - `/wedsync/src/app/api/chatbot/knowledge/search/route.ts`

### TECHNICAL DESIGN

#### Database Schema Required
```sql
-- Main knowledge base with vector embeddings
CREATE TABLE knowledge_base (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  vendor_id UUID NOT NULL REFERENCES suppliers(id),
  content TEXT NOT NULL,
  embedding vector(1536), -- OpenAI text-embedding-ada-002 dimensions
  source_type TEXT NOT NULL CHECK (source_type IN ('faq', 'article', 'form', 'website')),
  source_id UUID, -- Reference to original content (faq_id, article_id, etc.)
  metadata JSONB DEFAULT '{}',
  priority_weight DECIMAL(3,2) DEFAULT 1.00,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Vector similarity search index (requires pgvector extension)
CREATE INDEX ON knowledge_base USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Performance tracking for search results
CREATE TABLE knowledge_search_analytics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  vendor_id UUID NOT NULL REFERENCES suppliers(id),
  search_query TEXT NOT NULL,
  results_found INTEGER NOT NULL,
  top_result_similarity DECIMAL(5,4),
  user_feedback TEXT CHECK (user_feedback IN ('helpful', 'not_helpful', 'partially_helpful')),
  response_time_ms INTEGER,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Source priority configuration per vendor
CREATE TABLE knowledge_source_weights (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  vendor_id UUID NOT NULL REFERENCES suppliers(id),
  source_type TEXT NOT NULL,
  weight DECIMAL(3,2) NOT NULL DEFAULT 1.00,
  enabled BOOLEAN DEFAULT true,
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(vendor_id, source_type)
);

CREATE INDEX idx_knowledge_vendor ON knowledge_base(vendor_id);
CREATE INDEX idx_knowledge_source_type ON knowledge_base(source_type);
CREATE INDEX idx_search_analytics_vendor ON knowledge_search_analytics(vendor_id);
```

#### API Endpoints Required
```typescript
// Knowledge base search interface
interface SearchResult {
  id: string;
  content: string;
  source_type: 'faq' | 'article' | 'form' | 'website';
  source_id: string;
  similarity: number;
  finalScore: number;
  metadata: {
    title?: string;
    category?: string;
    lastUpdated: Date;
  };
}

interface KnowledgeIndexRequest {
  content: string;
  sourceType: 'faq' | 'article' | 'form' | 'website';
  sourceId: string;
  vendorId: string;
  metadata?: {
    title?: string;
    category?: string;
    tags?: string[];
  };
}

// POST /api/chatbot/knowledge/index - Index new content
// GET /api/chatbot/knowledge/search?q=:query&vendor_id=:id - Search knowledge base
// PUT /api/chatbot/knowledge/:id - Update existing knowledge
// DELETE /api/chatbot/knowledge/:id - Remove from knowledge base
// POST /api/chatbot/knowledge/bulk-index - Bulk index multiple items
```

#### Frontend Components Required
- **KnowledgeBaseManager**: Main interface for managing knowledge base content
- **ContentIndexer**: Upload and index new content with metadata
- **SourcePriorityControls**: Configure weights for different content sources
- **KnowledgeSearchPreview**: Test search functionality and preview results
- **AnalyticsDashboard**: Show search performance and knowledge gaps
- **BulkIndexingInterface**: Process multiple documents at once

#### Integration Points
- **KnowledgeSearch**: Core vector search using OpenAI embeddings and pgvector
- **ContentChunker**: Split large content into searchable chunks
- **SourcePrioritizer**: Weight results based on content source and quality
- **FAQ Management**: Auto-index FAQ updates
- **Article System**: Auto-index new articles and updates
- **Chatbot Service**: Provide search results for AI responses

### CODE EXAMPLES

#### Vector Search Implementation
```typescript
class KnowledgeSearch {
  async indexContent(content: string, metadata: KnowledgeIndexRequest) {
    // Generate embedding for content
    const embedding = await openai.embeddings.create({
      model: 'text-embedding-ada-002',
      input: content
    });
    
    // Store in database with vector
    await supabase.from('knowledge_base').insert({
      content,
      embedding: embedding.data[0].embedding,
      source_type: metadata.sourceType,
      source_id: metadata.sourceId,
      vendor_id: metadata.vendorId,
      metadata: metadata.metadata || {},
      priority_weight: this.getSourceWeight(metadata.sourceType)
    });
  }
  
  async search(query: string, vendorId: string): Promise<SearchResult[]> {
    // Generate query embedding
    const queryEmbedding = await openai.embeddings.create({
      model: 'text-embedding-ada-002',
      input: query
    });
    
    // Use Supabase vector similarity search
    const { data, error } = await supabase.rpc('match_knowledge', {
      query_embedding: queryEmbedding.data[0].embedding,
      vendor_id: vendorId,
      match_threshold: 0.8,
      match_count: 5
    });
    
    if (error) throw error;
    
    // Apply source prioritization
    return this.sourcePrioritizer.rankResults(data || []);
  }
}
```

#### Content Chunking Strategy
```typescript
class ContentChunker {
  splitIntoChunks(content: string, maxTokens: number = 500): string[] {
    const sentences = content.split(/[.!?]+/);
    const chunks: string[] = [];
    let currentChunk = '';
    
    for (const sentence of sentences) {
      const tokenCount = this.estimateTokens(currentChunk + sentence);
      
      if (tokenCount > maxTokens && currentChunk.length > 0) {
        chunks.push(currentChunk.trim());
        currentChunk = sentence;
      } else {
        currentChunk += (currentChunk ? '. ' : '') + sentence;
      }
    }
    
    if (currentChunk.trim()) {
      chunks.push(currentChunk.trim());
    }
    
    return chunks.filter(chunk => chunk.length > 10); // Filter very short chunks
  }
  
  private estimateTokens(text: string): number {
    // Rough estimation: 1 token â‰ˆ 4 characters for English text
    return Math.ceil(text.length / 4);
  }
}
```

#### Source Prioritization Logic
```typescript
class SourcePrioritizer {
  rankResults(results: SearchResult[]): SearchResult[] {
    return results
      .map(result => ({
        ...result,
        finalScore: result.similarity * this.getSourceWeight(result.source_type)
      }))
      .sort((a, b) => b.finalScore - a.finalScore)
      .slice(0, 10); // Return top 10 results
  }
  
  private getSourceWeight(sourceType: string): number {
    const weights = {
      'faq': 1.0,        // Highest priority - curated Q&A content
      'article': 0.8,    // High priority - detailed explanations
      'form': 0.6,       // Medium priority - process information
      'website': 0.4     // Lower priority - general content
    };
    
    return weights[sourceType] || 0.2;
  }
}
```

### MCP SERVER USAGE
- **Context7 MCP**: Fetch OpenAI embeddings API documentation and pgvector setup guides
- **Supabase MCP**: Apply database migrations and configure vector extensions
- **PostgreSQL MCP**: Test vector similarity search functions and performance
- **GitHub MCP**: Create feature branch and track implementation progress

Required Context7 queries:
```graphql
query {
  searchDocs(query: "OpenAI embeddings text-embedding-ada-002") {
    nodes {
      title
      content
      href
    }
  }
}
```

Required Supabase operations:
```typescript
// Enable pgvector extension
supabase.apply_migration(`CREATE EXTENSION IF NOT EXISTS vector;`);

// Create vector search function
supabase.apply_migration(`
CREATE OR REPLACE FUNCTION match_knowledge(
  query_embedding vector(1536),
  vendor_id uuid,
  match_threshold float,
  match_count int
)
RETURNS TABLE (
  id uuid,
  content text,
  source_type text,
  source_id uuid,
  similarity float
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    knowledge_base.id,
    knowledge_base.content,
    knowledge_base.source_type,
    knowledge_base.source_id,
    1 - (knowledge_base.embedding <=> query_embedding) AS similarity
  FROM knowledge_base
  WHERE knowledge_base.vendor_id = vendor_id
    AND 1 - (knowledge_base.embedding <=> query_embedding) > match_threshold
  ORDER BY knowledge_base.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;`);
```

### TEST REQUIREMENTS

#### Unit Tests
- **KnowledgeSearch.indexContent()**: Test content embedding and storage
- **KnowledgeSearch.search()**: Test vector similarity search accuracy
- **ContentChunker.splitIntoChunks()**: Test chunking logic with various content types
- **SourcePrioritizer.rankResults()**: Test result ranking and weighting
- **Vector search function**: Test pgvector similarity calculations

#### Integration Tests
- **Full indexing flow**: Content â†’ Chunking â†’ Embedding â†’ Storage â†’ Search
- **Database operations**: Test vector index creation and search performance
- **API endpoints**: Test indexing and search request/response formats
- **Auto-indexing**: Test automatic indexing when FAQs/articles are updated

#### Performance Tests
- **Vector search speed**: Ensure search completes within 200ms for typical queries
- **Bulk indexing performance**: Test indexing 100+ documents efficiently
- **Database scalability**: Test with 10,000+ knowledge base entries per vendor
- **Memory usage**: Monitor embedding storage and retrieval performance

#### E2E Tests
```typescript
test('Vendor indexes FAQ and searches knowledge base', async ({ page }) => {
  // Index some FAQ content
  await page.goto('/dashboard/knowledge-base');
  await page.click('[data-testid="index-content"]');
  await page.selectOption('[data-testid="source-type"]', 'faq');
  await page.fill('[data-testid="content"]', 'Do you provide wireless microphones? Yes, we provide 4 wireless microphones for outdoor ceremonies.');
  await page.click('[data-testid="index-button"]');
  
  // Test search functionality
  await page.fill('[data-testid="search-query"]', 'microphones outdoor');
  await page.click('[data-testid="search-button"]');
  
  await expect(page.locator('[data-testid="search-results"]')).toBeVisible();
  await expect(page.locator('[data-testid="search-results"]')).toContainText('wireless microphones');
  await expect(page.locator('[data-testid="similarity-score"]')).toContainText('0.9'); // High similarity
});
```

### ACCEPTANCE CRITERIA
- [ ] System indexes content from FAQs, articles, forms, and website pages
- [ ] Vector search returns semantically relevant results with similarity scores above 0.8
- [ ] Content chunking splits large documents appropriately (max 500 tokens per chunk)
- [ ] Source prioritization weights FAQ content higher than website content
- [ ] Search completes within 200ms for typical queries
- [ ] Knowledge base isolates content by vendor (no data leakage)
- [ ] Auto-indexing updates knowledge base when source content changes
- [ ] Analytics track search performance and knowledge gaps
- [ ] API handles bulk indexing of multiple documents efficiently
- [ ] Integration with chatbot provides contextual, accurate responses

### DEPENDENCIES
- **Before:** FAQ Management System (WS-070) and Article Creation (WS-069) must be complete
- **After:** Chatbot System will use this knowledge base for intelligent responses
- **Parallel:** Content Personalization Engine (WS-209) may reference knowledge base for context

### ESTIMATED EFFORT
- **Backend Development:** 32 hours (vector search, chunking, prioritization logic)
- **Database Work:** 16 hours (pgvector setup, migrations, search functions)
- **Frontend Development:** 24 hours (management interface, search preview, analytics)
- **API Development:** 16 hours (indexing, search, bulk operations endpoints)
- **Integration Work:** 12 hours (auto-indexing, FAQ/article system integration)
- **Testing:** 24 hours (unit, integration, performance, E2E)
- **Total:** 124 hours across teams