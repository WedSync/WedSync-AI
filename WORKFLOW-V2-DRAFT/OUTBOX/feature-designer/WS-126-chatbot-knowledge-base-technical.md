# TECHNICAL SPECIFICATION: WS-126 - Chatbot Knowledge Base
## Generated by Feature Development Session - 2025-01-23

### USER STORY & BUSINESS CONTEXT (THINK HARD - BE FACTUAL)
**As a:** Wedding venue coordinator fielding 50+ client inquiries per week about setup times, policies, and amenities
**I want to:** Build a smart knowledge base that powers an AI chatbot to instantly answer common questions
**So that:** I reduce inquiry response time from 4 hours to instant and free up 15 hours per week for actual wedding coordination

**Real Wedding Scenario:**
A venue gets repeated questions about "What time can vendors start setup?" and "Do you allow candles?" Instead of typing the same answers 10 times per week, the venue's extracted FAQs, articles, and policies are embedded into a searchable knowledge base. When couples ask questions, the chatbot instantly retrieves the exact answer with source attribution, maintaining accuracy while providing 24/7 availability.

### SPECIFICATION SOURCE
- **Feature ID:** WS-126
- **Original Spec:** /CORE-SPECIFICATIONS/04-AI-INTEGRATION/04-Chatbot/01-knowledge-base md.md
- **Current Implementation:** 0% complete
- **Files to Modify:** None (new feature)
- **New Files to Create:**
  - /src/lib/ai/knowledge-base.ts
  - /src/lib/ai/vector-search.ts
  - /src/app/api/chatbot/knowledge/index/route.ts
  - /src/app/api/chatbot/knowledge/search/route.ts
  - /src/components/chatbot/KnowledgeManager.tsx
  - /src/types/knowledge-base.ts

### TECHNICAL DESIGN

#### Database Schema Required
```sql
-- Vector extension for PostgreSQL
CREATE EXTENSION IF NOT EXISTS vector;

-- Main knowledge base storage with vector embeddings
CREATE TABLE IF NOT EXISTS knowledge_base (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  vendor_id UUID REFERENCES user_profiles(id),
  content TEXT NOT NULL,
  embedding vector(1536), -- OpenAI ada-002 embedding size
  source_type TEXT NOT NULL CHECK (source_type IN ('faq', 'article', 'form', 'website')),
  source_id UUID,
  source_url TEXT,
  chunk_index INTEGER DEFAULT 0,
  token_count INTEGER,
  confidence_threshold NUMERIC(3,2) DEFAULT 0.8,
  last_updated TIMESTAMP DEFAULT NOW(),
  created_at TIMESTAMP DEFAULT NOW(),
  metadata JSONB DEFAULT '{}',
  is_active BOOLEAN DEFAULT true
);

-- Vector similarity search index
CREATE INDEX IF NOT EXISTS knowledge_base_embedding_idx 
ON knowledge_base USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);

-- Source priority and performance tracking
CREATE TABLE IF NOT EXISTS knowledge_source_weights (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  vendor_id UUID REFERENCES user_profiles(id),
  source_type TEXT NOT NULL,
  priority_weight NUMERIC(3,2) DEFAULT 1.0,
  performance_score NUMERIC(3,2) DEFAULT 0.0,
  usage_count INTEGER DEFAULT 0,
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Search performance analytics
CREATE TABLE IF NOT EXISTS knowledge_search_analytics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  vendor_id UUID REFERENCES user_profiles(id),
  query_text TEXT NOT NULL,
  results_count INTEGER,
  top_result_similarity NUMERIC(3,2),
  response_time_ms INTEGER,
  user_feedback BOOLEAN,
  created_at TIMESTAMP DEFAULT NOW()
);
```

#### API Endpoints Required
```typescript
// POST /api/chatbot/knowledge/index
interface IndexKnowledgeRequest {
  content: string;
  sourceType: 'faq' | 'article' | 'form' | 'website';
  sourceId: string;
  sourceUrl?: string;
  vendorId: string;
  metadata?: Record<string, any>;
}

interface IndexKnowledgeResponse {
  success: boolean;
  data: {
    knowledgeId: string;
    chunksCreated: number;
    embeddingGenerated: boolean;
  };
}

// GET /api/chatbot/knowledge/search
interface SearchKnowledgeRequest {
  query: string;
  vendorId: string;
  limit?: number;
  minSimilarity?: number;
  sourceTypes?: string[];
}

interface SearchKnowledgeResponse {
  success: boolean;
  data: {
    results: KnowledgeSearchResult[];
    totalResults: number;
    searchTime: number;
  };
}
```

#### Frontend Components Required
```typescript
// Component: KnowledgeManager
// Location: /src/components/chatbot/KnowledgeManager.tsx

interface KnowledgeManagerProps {
  vendorId: string;
  onKnowledgeUpdated: () => void;
}

interface KnowledgeSearchResult {
  id: string;
  content: string;
  similarity: number;
  sourceType: string;
  sourceUrl?: string;
  metadata: Record<string, any>;
  finalScore: number;
}

interface KnowledgeBase {
  id: string;
  content: string;
  sourceType: string;
  tokenCount: number;
  isActive: boolean;
  lastUpdated: string;
}

// Key functionality:
- Real-time knowledge indexing interface
- Vector similarity search testing
- Source priority weight management
- Knowledge base analytics dashboard
- Content chunking preview and optimization
```

#### Integration Points
```typescript
// Service: KnowledgeBaseService
// Dependencies: OpenAI Embeddings, Supabase Vector, Content Processing

class KnowledgeBaseService {
  async indexContent(request: IndexKnowledgeRequest): Promise<string[]> {
    // Content chunking and preprocessing
    // OpenAI embedding generation
    // Vector storage with metadata
    // Source priority weighting
  }
  
  async searchKnowledge(query: string, vendorId: string): Promise<KnowledgeSearchResult[]> {
    // Query embedding generation
    // Vector similarity search
    // Source-weighted ranking
    // Performance analytics tracking
  }
}
```

### CODE EXAMPLES

#### Example 1: Vector Embeddings and Search
```typescript
// ACTUAL CODE PATTERN TO FOLLOW:
import { OpenAI } from 'openai';
import { supabase } from '@/lib/supabase';

export class KnowledgeSearch {
  private openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });

  async indexContent(
    content: string, 
    sourceType: string, 
    vendorId: string,
    metadata: any = {}
  ): Promise<string[]> {
    // Step 1: Split content into optimally-sized chunks
    const chunks = this.splitIntoChunks(content, 500);
    const knowledgeIds: string[] = [];
    
    // Step 2: Generate embeddings for each chunk
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      try {
        const embeddingResponse = await this.openai.embeddings.create({
          model: 'text-embedding-ada-002',
          input: chunk
        });
        
        const embedding = embeddingResponse.data[0].embedding;
        
        // Step 3: Store chunk with embedding in database
        const { data, error } = await supabase
          .from('knowledge_base')
          .insert({
            vendor_id: vendorId,
            content: chunk,
            embedding: embedding,
            source_type: sourceType,
            source_id: metadata.sourceId,
            source_url: metadata.sourceUrl,
            chunk_index: i,
            token_count: this.estimateTokens(chunk),
            metadata: metadata
          })
          .select('id')
          .single();
          
        if (error) throw error;
        knowledgeIds.push(data.id);
        
      } catch (error) {
        console.error(`Failed to index chunk ${i}:`, error);
      }
    }
    
    return knowledgeIds;
  }
  
  async search(query: string, vendorId: string, options: {
    limit?: number;
    minSimilarity?: number;
    sourceTypes?: string[];
  } = {}): Promise<KnowledgeSearchResult[]> {
    // Step 1: Generate query embedding
    const queryEmbeddingResponse = await this.openai.embeddings.create({
      model: 'text-embedding-ada-002',
      input: query
    });
    
    const queryEmbedding = queryEmbeddingResponse.data[0].embedding;
    
    // Step 2: Perform vector similarity search
    const { data, error } = await supabase.rpc('match_knowledge', {
      query_embedding: queryEmbedding,
      vendor_id: vendorId,
      match_threshold: options.minSimilarity || 0.8,
      match_count: options.limit || 5,
      source_type_filter: options.sourceTypes
    });
    
    if (error) throw error;
    
    // Step 3: Apply source weighting and ranking
    const rankedResults = await this.rankResults(data, vendorId);
    
    // Step 4: Log analytics
    await this.logSearchAnalytics(query, vendorId, rankedResults);
    
    return rankedResults;
  }
  
  private splitIntoChunks(content: string, maxTokens: number = 500): string[] {
    // Smart chunking that preserves sentence boundaries
    const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 0);
    const chunks: string[] = [];
    let currentChunk = '';
    
    for (const sentence of sentences) {
      const testChunk = currentChunk + (currentChunk ? '. ' : '') + sentence.trim();
      const tokenCount = this.estimateTokens(testChunk);
      
      if (tokenCount > maxTokens && currentChunk.length > 0) {
        chunks.push(currentChunk);
        currentChunk = sentence.trim();
      } else {
        currentChunk = testChunk;
      }
    }
    
    if (currentChunk.trim()) {
      chunks.push(currentChunk);
    }
    
    return chunks.filter(chunk => chunk.length > 10); // Filter out tiny chunks
  }
  
  private estimateTokens(text: string): number {
    // Rough estimation: 1 token â‰ˆ 4 characters for English text
    return Math.ceil(text.length / 4);
  }
  
  private async rankResults(
    results: any[], 
    vendorId: string
  ): Promise<KnowledgeSearchResult[]> {
    // Get source weights for this vendor
    const { data: weights } = await supabase
      .from('knowledge_source_weights')
      .select('source_type, priority_weight')
      .eq('vendor_id', vendorId);
    
    const weightMap = new Map(
      weights?.map(w => [w.source_type, w.priority_weight]) || []
    );
    
    return results.map(result => ({
      id: result.id,
      content: result.content,
      similarity: result.similarity,
      sourceType: result.source_type,
      sourceUrl: result.source_url,
      metadata: result.metadata,
      finalScore: result.similarity * (weightMap.get(result.source_type) || 0.5)
    }))
    .sort((a, b) => b.finalScore - a.finalScore);
  }
}
```

### MCP SERVER USAGE

#### Required MCP Servers
- [ ] Context7: Load docs for OpenAI embeddings and vector operations
- [ ] Playwright: Test knowledge search interface and chatbot integration
- [ ] Filesystem: Access knowledge content files and caching

#### Context7 Queries Needed
```typescript
await mcp__context7__get-library-docs("/openai/openai-node", "embeddings", 3000);
await mcp__context7__get-library-docs("/supabase/vecs", "vector search", 2500);
```

### TEST REQUIREMENTS

#### Unit Tests Required
```typescript
describe('KnowledgeSearch', () => {
  it('should split content into optimal chunks preserving sentences', () => {
    const content = 'First sentence. Second sentence. Third very long sentence that exceeds token limit.';
    const chunks = knowledgeSearch.splitIntoChunks(content, 50);
    expect(chunks).toHaveLength(2);
    expect(chunks[0]).not.toContain('Third very long');
  });
  
  it('should rank search results by source priority', async () => {
    const mockResults = [
      { similarity: 0.9, source_type: 'website' },
      { similarity: 0.8, source_type: 'faq' }
    ];
    
    const ranked = await knowledgeSearch.rankResults(mockResults, 'vendor-123');
    expect(ranked[0].sourceType).toBe('faq'); // Higher priority despite lower similarity
  });
  
  it('should generate embeddings and store in vector database', async () => {
    const content = 'Wedding ceremony setup begins at 10 AM sharp.';
    const ids = await knowledgeSearch.indexContent(content, 'faq', 'vendor-123');
    
    expect(ids).toHaveLength(1);
    
    // Verify embedding was stored
    const { data } = await supabase
      .from('knowledge_base')
      .select('embedding')
      .eq('id', ids[0])
      .single();
      
    expect(data.embedding).toHaveLength(1536); // OpenAI ada-002 dimensions
  });
});
```

#### E2E Tests Required
```typescript
// Using Playwright MCP
test('Knowledge base management workflow', async () => {
  await mcp__playwright__browser_navigate({url: '/chatbot/knowledge'});
  await mcp__playwright__browser_type({
    element: 'Content Input',
    ref: 'textarea[name="content"]',
    text: 'Sample FAQ about wedding timing and setup procedures.'
  });
  await mcp__playwright__browser_click({element: 'Index Content Button', ref: 'button[type="submit"]'});
  await mcp__playwright__browser_wait_for({text: 'Content indexed successfully'});
  
  // Test search functionality
  await mcp__playwright__browser_type({
    element: 'Search Query Input',
    ref: 'input[name="searchQuery"]',
    text: 'wedding setup time'
  });
  await mcp__playwright__browser_click({element: 'Search Button', ref: 'button.search-btn'});
  await mcp__playwright__browser_wait_for({text: 'Sample FAQ about wedding timing'});
  await mcp__playwright__browser_snapshot();
});
```

### ACCEPTANCE CRITERIA
- [ ] Index content from multiple sources (FAQs, articles, forms, websites)
- [ ] Generate vector embeddings using OpenAI ada-002 model
- [ ] Achieve 90%+ search accuracy for wedding-related queries
- [ ] Support vector similarity search with cosine distance
- [ ] Implement source priority weighting system
- [ ] Process search queries within 500ms average response time
- [ ] Store and retrieve 10,000+ knowledge chunks per vendor
- [ ] Provide search analytics and performance metrics

### DEPENDENCIES
- Must complete after: WS-125 (FAQ Extraction provides knowledge content)
- Must complete before: Chatbot implementation features
- Shares code with: AI content processing and OpenAI integration infrastructure

### ESTIMATED EFFORT
- Team A Frontend: 16 hours (Knowledge management UI, search interface)
- Team B Backend: 24 hours (Vector embeddings, similarity search, database optimization)
- Team C Integration: 12 hours (Content processing, source weighting, analytics)
- Total: 52 hours