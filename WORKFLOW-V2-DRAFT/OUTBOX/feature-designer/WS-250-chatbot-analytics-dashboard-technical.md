# TECHNICAL SPECIFICATION: WS-250 - Chatbot Analytics Dashboard
## Generated by Feature Development Session - 2025-08-30

### USER STORY & BUSINESS CONTEXT (THINK HARD - BE FACTUAL)
**As a:** Wedding photographer using WedSync's AI chatbot to handle client inquiries
**I want to:** View analytics on how well my chatbot is performing and what clients are asking about
**So that:** I can improve my knowledge base, identify common pain points, and optimize my chatbot to better serve clients while reducing my manual support workload

**Real Wedding Scenario:**
A wedding photographer notices their inquiry volume has increased 40% but their conversion rate has dropped. Using the analytics dashboard, they discover the chatbot is failing to answer common questions about "outdoor ceremony backup plans" (asked 23 times, only 30% confidence). They can see this topic clusters with weather-related questions and add specific FAQ entries, improving resolution rates from 65% to 85% and reducing their manual response time by 3 hours per week.

### SPECIFICATION SOURCE
- **Feature ID:** WS-250
- **Original Spec:** /CORE-SPECIFICATIONS/04-AI-INTEGRATION/04-Chatbot/04-analytics md.md
- **Current Implementation:** 0% complete
- **Files to Modify:**
  - /wedsync/src/app/(dashboard)/analytics/page.tsx (new)
  - /wedsync/src/components/analytics/ChatbotMetrics.tsx (new)
  - /wedsync/src/app/api/analytics/chatbot/route.ts (new)
- **New Files to Create:**
  - /wedsync/src/lib/analytics/chatbot-analytics.ts
  - /wedsync/src/lib/analytics/query-clustering.ts  
  - /wedsync/src/components/analytics/MetricsChart.tsx
  - /wedsync/src/components/analytics/QueryClusterView.tsx
  - /wedsync/src/components/analytics/ConversationInsights.tsx

### TECHNICAL DESIGN

#### Database Schema Required
```sql
-- Enhanced chatbot analytics tracking
CREATE TABLE IF NOT EXISTS chatbot_analytics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  supplier_id UUID REFERENCES suppliers(id) ON DELETE CASCADE,
  client_id UUID REFERENCES clients(id),
  conversation_id UUID NOT NULL,
  query TEXT NOT NULL,
  response TEXT NOT NULL,
  confidence_score DECIMAL(3,2) CHECK (confidence_score >= 0 AND confidence_score <= 1),
  response_type TEXT NOT NULL CHECK (response_type IN ('direct', 'qualified', 'suggestions', 'escalation', 'error')),
  was_helpful BOOLEAN,
  client_feedback_rating INTEGER CHECK (client_feedback_rating >= 1 AND client_feedback_rating <= 5),
  client_feedback_text TEXT,
  follow_up_required BOOLEAN DEFAULT false,
  resolution_time_seconds INTEGER,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Conversation sessions for grouping related queries
CREATE TABLE IF NOT EXISTS chatbot_conversations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  supplier_id UUID REFERENCES suppliers(id) ON DELETE CASCADE,
  client_id UUID REFERENCES clients(id),
  session_start TIMESTAMPTZ DEFAULT NOW(),
  session_end TIMESTAMPTZ,
  total_queries INTEGER DEFAULT 0,
  resolved_queries INTEGER DEFAULT 0,
  escalated BOOLEAN DEFAULT false,
  client_satisfaction INTEGER CHECK (client_satisfaction >= 1 AND client_satisfaction <= 5),
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Query clusters for topic analysis
CREATE TABLE IF NOT EXISTS chatbot_query_clusters (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  supplier_id UUID REFERENCES suppliers(id) ON DELETE CASCADE,
  cluster_name TEXT NOT NULL,
  sample_queries TEXT[] NOT NULL,
  query_count INTEGER DEFAULT 0,
  avg_confidence DECIMAL(3,2),
  resolution_rate DECIMAL(3,2),
  suggested_improvements TEXT,
  last_analyzed TIMESTAMPTZ DEFAULT NOW(),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(supplier_id, cluster_name)
);

-- Performance metrics summary (for dashboard optimization)
CREATE TABLE IF NOT EXISTS chatbot_metrics_summary (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  supplier_id UUID REFERENCES suppliers(id) ON DELETE CASCADE,
  date_period DATE NOT NULL,
  period_type TEXT NOT NULL CHECK (period_type IN ('daily', 'weekly', 'monthly')),
  total_conversations INTEGER DEFAULT 0,
  total_queries INTEGER DEFAULT 0,
  resolution_rate DECIMAL(3,2),
  avg_confidence DECIMAL(3,2),
  escalation_rate DECIMAL(3,2),
  avg_conversation_length DECIMAL(3,2),
  client_satisfaction_avg DECIMAL(3,2),
  top_topics TEXT[],
  improvement_suggestions TEXT[],
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(supplier_id, date_period, period_type)
);

-- Indexes for performance
CREATE INDEX IF NOT EXISTS idx_analytics_supplier_date ON chatbot_analytics(supplier_id, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_conversations_supplier_date ON chatbot_conversations(supplier_id, session_start DESC);
CREATE INDEX IF NOT EXISTS idx_metrics_supplier_period ON chatbot_metrics_summary(supplier_id, date_period DESC, period_type);
CREATE INDEX IF NOT EXISTS idx_analytics_conversation ON chatbot_analytics(conversation_id);
CREATE INDEX IF NOT EXISTS idx_analytics_helpful ON chatbot_analytics(supplier_id, was_helpful) WHERE was_helpful IS NOT NULL;
```

#### API Endpoints Required
```typescript
// GET /api/analytics/chatbot/overview
interface ChatbotOverviewResponse {
  success: boolean;
  data: {
    totalConversations: number;
    totalQueries: number;
    resolutionRate: number;
    avgConfidence: number;
    escalationRate: number;
    clientSatisfaction: number;
    trendData: Array<{
      date: string;
      conversations: number;
      resolutionRate: number;
      satisfaction: number;
    }>;
  };
  timeRange: {
    start: string;
    end: string;
  };
}

// GET /api/analytics/chatbot/query-clusters
interface QueryClustersResponse {
  success: boolean;
  clusters: Array<{
    id: string;
    name: string;
    sampleQueries: string[];
    queryCount: number;
    avgConfidence: number;
    resolutionRate: number;
    suggestedImprovements: string[];
    trend: 'increasing' | 'stable' | 'decreasing';
  }>;
  totalClusters: number;
}

// GET /api/analytics/chatbot/performance
interface PerformanceMetricsResponse {
  success: boolean;
  metrics: {
    byHour: Array<{ hour: number; queries: number; resolution: number }>;
    byDayOfWeek: Array<{ day: string; queries: number; satisfaction: number }>;
    byConfidenceRange: Array<{ range: string; count: number; helpful: number }>;
    commonFailureReasons: Array<{ reason: string; count: number; examples: string[] }>;
  };
}

// POST /api/analytics/chatbot/feedback
interface ChatbotFeedbackRequest {
  analyticsId: string;
  wasHelpful: boolean;
  rating?: number;
  feedback?: string;
}

// GET /api/analytics/chatbot/export
interface ExportAnalyticsRequest {
  format: 'csv' | 'pdf';
  dateRange: {
    start: string;
    end: string;
  };
  includeRawData: boolean;
}
```

#### Frontend Components Required
```typescript
// Component: ChatbotMetrics
// Location: /src/components/analytics/ChatbotMetrics.tsx

interface ChatbotMetricsProps {
  supplierId: string;
  timeRange: {
    start: Date;
    end: Date;
  };
  refreshInterval?: number;
}

// Key functionality:
- Display key performance indicators (KPIs) with trend indicators
- Show real-time metrics updates via Supabase real-time subscriptions
- Interactive charts for conversation volume, resolution rates, confidence scores
- Export functionality for reports
- Mobile-responsive cards layout

// Component: QueryClusterView
// Location: /src/components/analytics/QueryClusterView.tsx

interface QueryClusterViewProps {
  clusters: QueryCluster[];
  onClusterSelect: (cluster: QueryCluster) => void;
  onImprovementSuggestion: (clusterId: string, suggestion: string) => void;
}

// Key functionality:
- Visual representation of query topics with bubble chart
- Drill-down capability to see individual queries in cluster
- Suggested improvements with action buttons
- Color-coding by resolution rate (green: high, yellow: medium, red: low)
```

#### Integration Points
```typescript
// Service: ChatbotAnalyticsService
// Dependencies: OpenAI embeddings API, Analytics database, Real-time subscriptions

class ChatbotAnalyticsService {
  async recordChatInteraction(interaction: ChatInteraction) {
    // Record individual query and response
    const analyticsRecord = await this.createAnalyticsRecord(interaction);
    
    // Update conversation session
    await this.updateConversationSession(interaction.conversationId);
    
    // Process for clustering (async)
    await this.queueForClustering(interaction.query, interaction.supplierId);
    
    // Update real-time dashboard
    await this.broadcastMetricsUpdate(interaction.supplierId);
  }

  async generateQueryClusters(supplierId: string) {
    // Get recent queries for clustering
    const queries = await this.getRecentQueries(supplierId);
    
    // Generate embeddings for semantic clustering
    const clusters = await this.clusterQueries(queries);
    
    // Store cluster analysis
    await this.storeClusters(supplierId, clusters);
    
    // Generate improvement suggestions
    await this.generateClusterInsights(supplierId, clusters);
  }

  async generateWeeklyReport(supplierId: string) {
    // Aggregate metrics for past week
    const metrics = await this.calculateWeeklyMetrics(supplierId);
    
    // Identify trends and anomalies
    const insights = await this.generateInsights(metrics);
    
    // Create improvement suggestions
    const suggestions = await this.generateSuggestions(insights);
    
    return { metrics, insights, suggestions };
  }
}

// Service: QueryClusteringService  
// Dependencies: OpenAI embeddings, Vector similarity, K-means clustering

class QueryClusteringService {
  async clusterQueries(queries: string[], supplierId: string) {
    // Generate embeddings for all queries
    const embeddings = await this.generateEmbeddings(queries);
    
    // Perform k-means clustering
    const clusters = await this.performClustering(embeddings, queries);
    
    // Label clusters with descriptive names
    const labeledClusters = await this.labelClusters(clusters);
    
    return labeledClusters;
  }

  private async generateEmbeddings(queries: string[]) {
    const batches = this.chunkArray(queries, 100); // Process in batches
    const allEmbeddings = [];
    
    for (const batch of batches) {
      const response = await this.openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: batch
      });
      allEmbeddings.push(...response.data.map(d => d.embedding));
    }
    
    return allEmbeddings;
  }
}
```

### CODE EXAMPLES

#### Example 1: Real-time Analytics Dashboard
```typescript
// ACTUAL CODE PATTERN TO FOLLOW:
import { useState, useEffect } from 'react';
import { supabase } from '@/lib/supabase';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer } from 'recharts';

interface ChatbotMetricsProps {
  supplierId: string;
  timeRange: { start: Date; end: Date };
}

export function ChatbotMetrics({ supplierId, timeRange }: ChatbotMetricsProps) {
  const [metrics, setMetrics] = useState<ChatbotMetrics | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    loadMetrics();
    
    // Set up real-time subscription for metrics updates
    const subscription = supabase
      .channel(`metrics:${supplierId}`)
      .on('postgres_changes', 
          { 
            event: 'INSERT', 
            schema: 'public', 
            table: 'chatbot_analytics',
            filter: `supplier_id=eq.${supplierId}`
          }, 
          () => {
            // Refresh metrics when new data arrives
            loadMetrics();
          }
      )
      .subscribe();

    return () => {
      subscription.unsubscribe();
    };
  }, [supplierId, timeRange]);

  const loadMetrics = async () => {
    try {
      setLoading(true);
      
      // Fetch overview metrics
      const { data: overview, error: overviewError } = await supabase
        .from('chatbot_metrics_summary')
        .select('*')
        .eq('supplier_id', supplierId)
        .gte('date_period', timeRange.start.toISOString().split('T')[0])
        .lte('date_period', timeRange.end.toISOString().split('T')[0])
        .order('date_period', { ascending: true });

      if (overviewError) throw overviewError;

      // Calculate aggregated metrics
      const totalConversations = overview?.reduce((sum, day) => sum + day.total_conversations, 0) || 0;
      const totalQueries = overview?.reduce((sum, day) => sum + day.total_queries, 0) || 0;
      const avgResolution = overview?.reduce((sum, day) => sum + day.resolution_rate, 0) / (overview?.length || 1);
      const avgConfidence = overview?.reduce((sum, day) => sum + day.avg_confidence, 0) / (overview?.length || 1);
      
      // Prepare trend data for charts
      const trendData = overview?.map(day => ({
        date: day.date_period,
        conversations: day.total_conversations,
        resolutionRate: day.resolution_rate * 100,
        confidence: day.avg_confidence * 100,
        satisfaction: day.client_satisfaction_avg * 100
      })) || [];

      setMetrics({
        totalConversations,
        totalQueries,
        resolutionRate: avgResolution,
        avgConfidence,
        trendData
      });
      
    } catch (error) {
      console.error('Error loading chatbot metrics:', error);
      setError('Failed to load analytics data');
    } finally {
      setLoading(false);
    }
  };

  if (loading) return <div className="animate-pulse">Loading analytics...</div>;
  if (error) return <div className="text-red-500">Error: {error}</div>;
  if (!metrics) return <div>No data available</div>;

  return (
    <div className="space-y-6">
      {/* KPI Cards */}
      <div className="grid grid-cols-1 md:grid-cols-4 gap-4">
        <Card>
          <CardHeader className="pb-2">
            <CardTitle className="text-sm font-medium text-gray-500">Total Conversations</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="text-2xl font-bold">{metrics.totalConversations}</div>
            <p className="text-xs text-gray-500 mt-1">
              {metrics.totalQueries} total queries
            </p>
          </CardContent>
        </Card>
        
        <Card>
          <CardHeader className="pb-2">
            <CardTitle className="text-sm font-medium text-gray-500">Resolution Rate</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="text-2xl font-bold text-green-600">
              {(metrics.resolutionRate * 100).toFixed(1)}%
            </div>
            <p className="text-xs text-gray-500 mt-1">
              Questions answered successfully
            </p>
          </CardContent>
        </Card>
        
        <Card>
          <CardHeader className="pb-2">
            <CardTitle className="text-sm font-medium text-gray-500">Avg Confidence</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="text-2xl font-bold text-blue-600">
              {(metrics.avgConfidence * 100).toFixed(1)}%
            </div>
            <p className="text-xs text-gray-500 mt-1">
              AI response confidence
            </p>
          </CardContent>
        </Card>
        
        <Card>
          <CardHeader className="pb-2">
            <CardTitle className="text-sm font-medium text-gray-500">Queries/Day</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="text-2xl font-bold">
              {Math.round(metrics.totalQueries / (metrics.trendData.length || 1))}
            </div>
            <p className="text-xs text-gray-500 mt-1">
              Average daily volume
            </p>
          </CardContent>
        </Card>
      </div>

      {/* Trend Chart */}
      <Card>
        <CardHeader>
          <CardTitle>Performance Trends</CardTitle>
        </CardHeader>
        <CardContent>
          <ResponsiveContainer width="100%" height={300}>
            <LineChart data={metrics.trendData}>
              <CartesianGrid strokeDasharray="3 3" />
              <XAxis dataKey="date" />
              <YAxis />
              <Tooltip />
              <Line 
                type="monotone" 
                dataKey="resolutionRate" 
                stroke="#10b981" 
                strokeWidth={2}
                name="Resolution Rate (%)"
              />
              <Line 
                type="monotone" 
                dataKey="confidence" 
                stroke="#3b82f6" 
                strokeWidth={2}
                name="Confidence (%)"
              />
            </LineChart>
          </ResponsiveContainer>
        </CardContent>
      </Card>
    </div>
  );
}
```

#### Example 2: Query Clustering Analysis
```typescript
// ACTUAL CODE PATTERN TO FOLLOW:
import { OpenAI } from 'openai';
import { supabase } from '@/lib/supabase';

interface QueryCluster {
  id: string;
  name: string;
  queries: string[];
  avgConfidence: number;
  resolutionRate: number;
  count: number;
}

export class QueryClusteringService {
  private openai: OpenAI;

  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
  }

  async analyzeQueryPatterns(supplierId: string, timeRangeDays: number = 30) {
    try {
      // Get recent queries for analysis
      const { data: queries, error } = await supabase
        .from('chatbot_analytics')
        .select('query, confidence_score, was_helpful')
        .eq('supplier_id', supplierId)
        .gte('created_at', new Date(Date.now() - timeRangeDays * 24 * 60 * 60 * 1000).toISOString())
        .limit(1000);

      if (error) throw error;
      if (!queries?.length) return [];

      // Extract unique queries to avoid duplicates
      const uniqueQueries = Array.from(new Map(
        queries.map(q => [q.query.toLowerCase().trim(), q])
      ).values());

      // Generate embeddings for semantic clustering
      const embeddings = await this.generateEmbeddings(
        uniqueQueries.map(q => q.query)
      );

      // Perform clustering using k-means
      const clusters = await this.performKMeansClustering(
        embeddings, 
        uniqueQueries,
        Math.min(8, Math.ceil(uniqueQueries.length / 10)) // Dynamic cluster count
      );

      // Analyze each cluster for insights
      const analyzedClusters = await Promise.all(
        clusters.map(cluster => this.analyzeCluster(cluster, supplierId))
      );

      // Store cluster analysis in database
      await this.storeClusters(supplierId, analyzedClusters);

      return analyzedClusters;

    } catch (error) {
      console.error('Error analyzing query patterns:', error);
      throw error;
    }
  }

  private async generateEmbeddings(queries: string[]): Promise<number[][]> {
    const batchSize = 100;
    const embeddings: number[][] = [];

    // Process in batches to avoid API limits
    for (let i = 0; i < queries.length; i += batchSize) {
      const batch = queries.slice(i, i + batchSize);
      
      const response = await this.openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: batch
      });

      embeddings.push(...response.data.map(d => d.embedding));
      
      // Add delay to respect rate limits
      if (i + batchSize < queries.length) {
        await this.delay(100);
      }
    }

    return embeddings;
  }

  private async performKMeansClustering(
    embeddings: number[][], 
    queries: any[], 
    k: number
  ): Promise<QueryCluster[]> {
    // Simplified k-means clustering implementation
    // In production, consider using a more robust clustering library
    
    const clusters: QueryCluster[] = [];
    
    // Initialize centroids randomly
    const centroids = this.initializeCentroids(embeddings, k);
    
    // Perform clustering iterations
    for (let iteration = 0; iteration < 50; iteration++) {
      const assignments = this.assignToClusters(embeddings, centroids);
      const newCentroids = this.updateCentroids(embeddings, assignments, k);
      
      // Check for convergence
      if (this.centroidsConverged(centroids, newCentroids)) {
        break;
      }
      
      centroids.splice(0, centroids.length, ...newCentroids);
    }

    // Build final clusters with query data
    const assignments = this.assignToClusters(embeddings, centroids);
    
    for (let i = 0; i < k; i++) {
      const clusterQueries = queries.filter((_, index) => assignments[index] === i);
      
      if (clusterQueries.length > 0) {
        clusters.push({
          id: `cluster-${i}`,
          name: await this.generateClusterName(clusterQueries.map(q => q.query)),
          queries: clusterQueries.map(q => q.query),
          avgConfidence: clusterQueries.reduce((sum, q) => sum + q.confidence_score, 0) / clusterQueries.length,
          resolutionRate: clusterQueries.filter(q => q.was_helpful).length / clusterQueries.length,
          count: clusterQueries.length
        });
      }
    }

    return clusters.filter(c => c.count >= 3); // Only return clusters with meaningful size
  }

  private async generateClusterName(queries: string[]): Promise<string> {
    // Use AI to generate descriptive cluster names
    const sampleQueries = queries.slice(0, 5).join('\n- ');
    
    try {
      const completion = await this.openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content: "You are analyzing wedding vendor chatbot queries. Generate a short, descriptive topic name (2-4 words) that captures the main theme of these related questions."
          },
          {
            role: "user",
            content: `Generate a topic name for these related questions:\n- ${sampleQueries}`
          }
        ],
        max_tokens: 10,
        temperature: 0.3
      });

      return completion.choices[0]?.message?.content?.trim() || 'Miscellaneous';
      
    } catch (error) {
      console.error('Error generating cluster name:', error);
      return 'Query Topic';
    }
  }

  private async analyzeCluster(cluster: QueryCluster, supplierId: string) {
    // Generate improvement suggestions for low-performing clusters
    const suggestions: string[] = [];
    
    if (cluster.resolutionRate < 0.7) {
      suggestions.push('Consider adding FAQ entries for this topic');
    }
    
    if (cluster.avgConfidence < 0.6) {
      suggestions.push('Review and improve knowledge base content');
    }
    
    if (cluster.count > 20) {
      suggestions.push('High volume topic - prioritize for knowledge base expansion');
    }

    return {
      ...cluster,
      suggestions,
      priority: this.calculatePriority(cluster)
    };
  }

  private calculatePriority(cluster: QueryCluster): 'high' | 'medium' | 'low' {
    const score = (cluster.count * 0.4) + ((1 - cluster.resolutionRate) * 0.6);
    
    if (score > 0.7) return 'high';
    if (score > 0.4) return 'medium';
    return 'low';
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // Simplified clustering helper methods
  private initializeCentroids(embeddings: number[][], k: number): number[][] {
    const centroids: number[][] = [];
    for (let i = 0; i < k; i++) {
      const randomIndex = Math.floor(Math.random() * embeddings.length);
      centroids.push([...embeddings[randomIndex]]);
    }
    return centroids;
  }

  private assignToClusters(embeddings: number[][], centroids: number[][]): number[] {
    return embeddings.map(embedding => {
      let minDistance = Infinity;
      let assignedCluster = 0;
      
      centroids.forEach((centroid, index) => {
        const distance = this.euclideanDistance(embedding, centroid);
        if (distance < minDistance) {
          minDistance = distance;
          assignedCluster = index;
        }
      });
      
      return assignedCluster;
    });
  }

  private updateCentroids(embeddings: number[][], assignments: number[], k: number): number[][] {
    const newCentroids: number[][] = [];
    
    for (let i = 0; i < k; i++) {
      const clusterEmbeddings = embeddings.filter((_, index) => assignments[index] === i);
      
      if (clusterEmbeddings.length > 0) {
        const centroid = new Array(clusterEmbeddings[0].length).fill(0);
        clusterEmbeddings.forEach(embedding => {
          embedding.forEach((value, index) => {
            centroid[index] += value;
          });
        });
        
        centroid.forEach((_, index) => {
          centroid[index] /= clusterEmbeddings.length;
        });
        
        newCentroids.push(centroid);
      } else {
        // Keep existing centroid if no points assigned
        newCentroids.push([...centroids[i]]);
      }
    }
    
    return newCentroids;
  }

  private euclideanDistance(a: number[], b: number[]): number {
    return Math.sqrt(a.reduce((sum, val, i) => sum + Math.pow(val - b[i], 2), 0));
  }

  private centroidsConverged(old: number[][], new_: number[][], threshold = 0.001): boolean {
    return old.every((oldCentroid, i) => 
      this.euclideanDistance(oldCentroid, new_[i]) < threshold
    );
  }
}
```

### MCP SERVER USAGE

#### Required MCP Servers
- [x] Ref MCP: Search docs for OpenAI embeddings, Recharts library, Supabase real-time
- [x] PostgreSQL MCP: Database operations for analytics storage and queries
- [x] Supabase MCP: Real-time subscriptions for live dashboard updates
- [x] Sequential Thinking MCP: Complex clustering algorithm planning and optimization strategies
- [x] Browser MCP: Interactive testing of dashboard components and chart interactions
- [ ] Filesystem MCP: Analytics report export and file management

#### Ref MCP Searches Needed
```bash
# Use Ref MCP to search for:
# - "OpenAI embeddings clustering best practices"
# - "Recharts responsive chart components"
# - "Supabase real-time subscriptions React"
# - "K-means clustering JavaScript implementation"
# - "Dashboard analytics UI/UX patterns"
```

#### Browser MCP Interactive Testing
```bash
# Use Browser MCP for:
# - Test dashboard loads correctly with sample data
# - Verify charts are responsive across screen sizes
# - Test real-time updates when new data arrives
# - Capture screenshots of different metric views
# - Test export functionality for reports
# - Verify query cluster drill-down interactions
# - Test time range filters and data refresh
```

#### Sequential Thinking MCP Planning (For Complex Features)
```yaml
# Use Sequential Thinking MCP to optimize analytics architecture:

# 1. Data Processing Strategy
- How to balance real-time updates vs performance?
- What aggregation levels provide most value to suppliers?
- How to handle large datasets without slow queries?

# 2. Clustering Algorithm Optimization
- What's the optimal number of clusters for wedding queries?
- How to balance semantic similarity with actionable insights?
- When to re-run clustering analysis for suppliers?

# 3. Dashboard Performance
- How to minimize API calls while keeping data fresh?
- What caching strategies work for time-series analytics?
- How to handle concurrent dashboard users efficiently?

# 4. Actionable Insights Generation
- What metrics indicate chatbot needs improvement?
- How to prioritize suggestions for suppliers?
- What threshold values trigger automated alerts?
```

### TEST REQUIREMENTS

#### Unit Tests Required
```typescript
describe('ChatbotAnalyticsService', () => {
  it('should calculate resolution rate correctly', async () => {
    const service = new ChatbotAnalyticsService();
    const metrics = await service.calculateMetrics('supplier-123', dateRange);
    expect(metrics.resolutionRate).toBeGreaterThanOrEqual(0);
    expect(metrics.resolutionRate).toBeLessThanOrEqual(1);
  });

  it('should aggregate conversation data properly', async () => {
    const service = new ChatbotAnalyticsService();
    const conversations = await service.getConversationMetrics('supplier-123');
    expect(conversations.avgLength).toBeGreaterThan(0);
    expect(conversations.handoffRate).toBeDefined();
  });
});

describe('QueryClusteringService', () => {
  it('should cluster similar queries together', async () => {
    const service = new QueryClusteringService();
    const queries = ['venue capacity', 'how many guests fit', 'venue size'];
    const clusters = await service.clusterQueries(queries, 'supplier-123');
    expect(clusters.length).toBeGreaterThan(0);
    expect(clusters[0].queries.length).toBeGreaterThanOrEqual(2);
  });

  it('should generate meaningful cluster names', async () => {
    const service = new QueryClusteringService();
    const clusterName = await service.generateClusterName([
      'What time should we arrive?',
      'When should the bridal party be ready?',
      'What is the ceremony schedule?'
    ]);
    expect(clusterName).toContain('timing' || 'schedule');
  });
});
```

#### E2E Tests Required  
```typescript
// Using Playwright MCP for automated testing
test('Analytics dashboard loads and displays metrics', async () => {
  await mcp__playwright__browser_navigate({url: '/analytics/chatbot'});
  
  // Verify key metrics are displayed
  await mcp__playwright__browser_wait_for({text: 'Total Conversations'});
  await mcp__playwright__browser_wait_for({text: 'Resolution Rate'});
  await mcp__playwright__browser_wait_for({text: 'Avg Confidence'});
  
  // Take screenshot for documentation
  await mcp__playwright__browser_take_screenshot({
    filename: 'chatbot-analytics-dashboard.png',
    fullPage: true
  });
});

test('Query cluster analysis shows insights', async () => {
  await mcp__playwright__browser_navigate({url: '/analytics/chatbot'});
  
  // Click on clusters tab
  await mcp__playwright__browser_click({
    element: 'clusters tab',
    ref: '[data-testid="clusters-tab"]'
  });
  
  // Verify clusters are displayed
  await mcp__playwright__browser_wait_for({text: 'Query Topics'});
  
  // Click on a cluster to see details
  await mcp__playwright__browser_click({
    element: 'first cluster',
    ref: '[data-testid="cluster-item"]:first-child'
  });
  
  // Verify cluster details modal opens
  await mcp__playwright__browser_wait_for({text: 'Sample Queries'});
  
  // Take screenshot of cluster analysis
  await mcp__playwright__browser_take_screenshot({
    filename: 'query-cluster-analysis.png'
  });
});

test('Real-time metrics update correctly', async () => {
  await mcp__playwright__browser_navigate({url: '/analytics/chatbot'});
  
  // Get initial conversation count
  const initialCount = await mcp__playwright__browser_evaluate({
    function: '() => document.querySelector("[data-testid=conversation-count]").textContent'
  });
  
  // Simulate new conversation via API
  // (This would be done via test data setup)
  
  // Wait for real-time update
  await mcp__playwright__browser_wait_for({
    time: 3 // Wait 3 seconds for real-time update
  });
  
  // Verify count increased
  const updatedCount = await mcp__playwright__browser_evaluate({
    function: '() => document.querySelector("[data-testid=conversation-count]").textContent'
  });
  
  expect(parseInt(updatedCount)).toBeGreaterThan(parseInt(initialCount));
});
```

#### Interactive Testing with Browser MCP
```typescript
// Use Browser MCP during development for immediate feedback
// 1. Test dashboard responsiveness
await browser_navigate('/analytics/chatbot');

// Desktop view
await browser_resize(1920, 1080);
await browser_take_screenshot('analytics-desktop.png');

// Tablet view  
await browser_resize(768, 1024);
await browser_take_screenshot('analytics-tablet.png');

// Mobile view
await browser_resize(375, 667);
await browser_take_screenshot('analytics-mobile.png');

// 2. Test chart interactions
await browser_click('[data-testid="chart-tooltip-trigger"]');
await browser_take_screenshot('chart-tooltip-active.png');

// 3. Test export functionality
await browser_click('[data-testid="export-button"]');
await browser_wait_for('Export Options');
await browser_click('[data-testid="export-csv"]');

// 4. Test time range filtering
const timeRanges = ['7d', '30d', '90d'];
for (const range of timeRanges) {
  await browser_click(`[data-testid="time-range-${range}"]`);
  await browser_wait_for('Loading');
  await browser_take_screenshot(`analytics-${range}.png`);
}
```

### ACCEPTANCE CRITERIA
- [x] **Real-time Dashboard**: Live metrics updates via Supabase real-time subscriptions
- [x] **Key Metrics Display**: Conversation volume, resolution rate, confidence scores, client satisfaction
- [x] **Query Clustering**: AI-powered semantic clustering of customer queries with descriptive topic names
- [x] **Trend Analysis**: Time-series charts showing performance trends over configurable date ranges
- [x] **Actionable Insights**: Automated suggestions for improving chatbot performance based on data patterns
- [x] **Export Functionality**: CSV and PDF export of analytics reports for supplier review
- [x] **Mobile Responsive**: Full dashboard functionality on mobile devices
- [ ] Performance: Dashboard loads within 3 seconds with 30 days of data
- [ ] Security: Analytics data access controlled by supplier RLS policies
- [ ] Accessibility: Charts and dashboard meet WCAG 2.1 AA standards with screen reader support
- [x] **Navigation Integration: Feature properly integrated into parent dashboard/navigation (MANDATORY for all UI features)**
  - [x] Analytics link added to supplier dashboard sidebar under "Insights" section
  - [x] Mobile navigation includes analytics tab with chat icon indicator
  - [x] Breadcrumb navigation shows "Dashboard > Analytics > Chatbot Performance"
  - [x] Active state highlighting when on analytics pages
  - [x] Accessibility labels for navigation items ("View chatbot analytics")
  - [x] Navigation integration verified with Browser MCP testing

### DEPENDENCIES
- Must complete after: WS-249 (Fallback Logic System) - uses fallback data for analytics
- Must complete before: WS-251 (Photography AI Intelligence) - analytics patterns inform AI training
- Shares code with: WS-054 (Journey Performance Analytics) - similar analytics infrastructure

### ESTIMATED EFFORT
- Team A Frontend: 28 hours (Dashboard components, charts, mobile responsive design)
- Team B Backend: 32 hours (Analytics service, clustering algorithms, real-time subscriptions)
- Team C Integration: 12 hours (OpenAI embeddings integration, export functionality)
- Team D Platform: 8 hours (Database optimization, caching strategy)
- Team E General: 16 hours (Testing, documentation, QA)
- Team F Workflows: 6 hours (Analytics workflow design and user training)
- Team G Performance: 8 hours (Query optimization, dashboard performance tuning)
- Total: 110 hours