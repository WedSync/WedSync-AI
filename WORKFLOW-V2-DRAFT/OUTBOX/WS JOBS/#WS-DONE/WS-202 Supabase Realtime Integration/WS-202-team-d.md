# TEAM D - ROUND 1: WS-202 - Supabase Realtime Integration
## 2025-01-20 - Development Round 1

**YOUR MISSION:** Implement performance optimization and infrastructure scaling for Supabase realtime integration including connection pooling, caching strategies, and high-availability architecture for peak wedding season loads
**FEATURE ID:** WS-202 (Track all work with this ID)
**TIME LIMIT:** 2-3 hours per round  
**THINK ULTRA HARD** about creating scalable realtime infrastructure that handles 200+ simultaneous connections per supplier with sub-500ms update latency during peak wedding coordination

## üö® CRITICAL: EVIDENCE OF REALITY REQUIREMENTS (NON-NEGOTIABLE)

**‚ö†Ô∏è MANDATORY: Before claiming completion, you MUST provide:**

1. **FILE EXISTENCE PROOF:**
```bash
ls -la $WS_ROOT/wedsync/src/lib/performance/realtime-connection-optimizer.ts
ls -la $WS_ROOT/wedsync/src/lib/performance/realtime-cache-manager.ts
ls -la $WS_ROOT/wedsync/src/lib/infrastructure/realtime-scaling-manager.ts
cat $WS_ROOT/wedsync/src/lib/performance/realtime-connection-optimizer.ts | head -20
```

2. **TYPECHECK RESULTS:**
```bash
npm run typecheck
# MUST show: "No errors found"
```

3. **TEST RESULTS:**
```bash
npm test realtime-performance
# MUST show: "All tests passing"
```

**Teams submitting hallucinated implementations will be rejected immediately.**

## üìö STEP 1: ENHANCED DOCUMENTATION & CODEBASE ANALYSIS (MANDATORY - 10 MINUTES!)

### A. SERENA PROJECT ACTIVATION (MINUTES 1-3)
```typescript
// CRITICAL: Activate Serena for semantic code understanding
await mcp__serena__activate_project("$WS_ROOT/wedsync");
await mcp__serena__switch_modes(["editing", "interactive"]);
await mcp__serena__check_onboarding_performed();

// Query performance and realtime patterns
await mcp__serena__search_for_pattern("performance.*realtime");
await mcp__serena__find_symbol("ConnectionOptimizer", "", true);
await mcp__serena__get_symbols_overview("src/lib/performance");
await mcp__serena__search_for_pattern("infrastructure.*scaling");
```

### B. REF MCP CURRENT DOCS (MINUTES 3-5)
```typescript
// Load documentation SPECIFIC to realtime performance
await mcp__Ref__ref_search_documentation("Supabase Realtime performance optimization scaling");
await mcp__Ref__ref_search_documentation("WebSocket connection pooling Node.js performance");
await mcp__Ref__ref_search_documentation("Redis caching realtime data patterns");
```

## üß† STEP 2A: SEQUENTIAL THINKING FOR PERFORMANCE PLANNING

### Use Sequential Thinking MCP for Scaling Analysis
```typescript
mcp__sequential-thinking__sequential_thinking({
  thought: "Realtime performance optimization requires multi-level approach: connection pooling for efficient WebSocket management, caching for subscription state and user data, auto-scaling for connection spikes, and monitoring for performance bottlenecks. I need to analyze: 1) Connection pool optimization for 200+ simultaneous connections, 2) Redis-based caching for realtime subscription state, 3) Auto-scaling infrastructure for peak wedding season, 4) Performance monitoring with sub-500ms latency requirements, 5) Memory optimization for long-running realtime connections.",
  nextThoughtNeeded: true,
  thoughtNumber: 1,
  totalThoughts: 5
});
```

## üöÄ STEP 2B: LAUNCH ENHANCED AGENTS WITH SPECIFIC MISSIONS

Launch these agents with comprehensive requirements:

1. **task-tracker-coordinator** - Break down realtime performance optimization tasks
2. **performance-optimization-expert** - Design caching and connection optimization
3. **devops-sre-engineer** - Handle infrastructure scaling and monitoring
4. **code-quality-guardian** - Maintain performance code standards
5. **test-automation-architect** - Performance testing and load validation for realtime
6. **documentation-chronicler** - Evidence-based performance documentation

## üîí SECURITY REQUIREMENTS (NON-NEGOTIABLE!)

### REALTIME PERFORMANCE SECURITY CHECKLIST:
- [ ] **Connection rate limiting** - Prevent DoS through connection spam
- [ ] **Cache security** - Secure Redis connections and realtime data encryption
- [ ] **Resource limits** - Prevent memory exhaustion from connection leaks
- [ ] **Connection authentication** - Validate user permissions for all connections
- [ ] **Performance logging** - No sensitive data in performance metrics
- [ ] **Auto-scaling security** - Secure infrastructure scaling triggers
- [ ] **Connection cleanup** - Automatic cleanup of abandoned connections
- [ ] **Cache invalidation security** - Prevent cache poisoning attacks

## üéØ TEAM D SPECIALIZATION: PERFORMANCE/INFRASTRUCTURE FOCUS

**PERFORMANCE/INFRASTRUCTURE RESPONSIBILITIES:**
- High-performance connection pooling and realtime optimization
- Caching strategies for subscription state and user data
- Infrastructure scaling for peak wedding season connection loads
- Connection monitoring and automated cleanup systems
- Performance SLA compliance and realtime latency optimization
- Mobile-optimized realtime connection management

### SPECIFIC DELIVERABLES FOR WS-202:

1. **Realtime Connection Optimizer:**
```typescript
// Location: $WS_ROOT/wedsync/src/lib/performance/realtime-connection-optimizer.ts
export class RealtimeConnectionOptimizer {
  private connectionPool: Map<string, RealtimeConnection> = new Map();
  private connectionMetrics: ConnectionMetricsTracker;
  private cleanupInterval: NodeJS.Timeout | null = null;
  
  constructor(private maxConnectionsPerUser: number = 5) {
    this.connectionMetrics = new ConnectionMetricsTracker();
    this.startConnectionCleanup();
  }
  
  // Optimize connection creation and reuse
  async optimizeConnectionCreation(
    userId: string,
    channelType: string,
    subscriptionConfig: SubscriptionConfig
  ): Promise<OptimizedConnection> {
    const connectionKey = `${userId}-${channelType}`;
    
    // Check for existing connection that can be reused
    const existingConnection = this.connectionPool.get(connectionKey);
    if (existingConnection && existingConnection.isHealthy) {
      // Reuse existing connection
      await this.addSubscriptionToConnection(existingConnection, subscriptionConfig);
      this.connectionMetrics.recordConnectionReuse(userId, channelType);
      return existingConnection;
    }
    
    // Create new optimized connection
    const newConnection = await this.createOptimizedConnection(
      userId,
      channelType,
      subscriptionConfig
    );
    
    // Add to connection pool with optimization
    this.connectionPool.set(connectionKey, newConnection);
    this.connectionMetrics.recordNewConnection(userId, channelType);
    
    return newConnection;
  }
  
  // Batch subscription management for efficiency
  async batchSubscriptionUpdates(
    userId: string,
    subscriptionBatch: SubscriptionBatch[]
  ): Promise<BatchResult> {
    const results: BatchResult = { successful: [], failed: [] };
    
    // Group subscriptions by connection type for efficiency
    const subscriptionGroups = this.groupSubscriptionsByType(subscriptionBatch);
    
    // Process each group in parallel
    const batchPromises = Object.entries(subscriptionGroups).map(
      async ([connectionType, subscriptions]) => {
        try {
          const connection = await this.optimizeConnectionCreation(
            userId,
            connectionType,
            { subscriptions }
          );
          
          const batchResult = await this.processBatchSubscriptions(
            connection,
            subscriptions
          );
          
          results.successful.push(...batchResult.successful);
          results.failed.push(...batchResult.failed);
          
        } catch (error) {
          console.error(`Batch subscription failed for ${connectionType}:`, error);
          results.failed.push(...subscriptions.map(sub => ({
            subscription: sub,
            error: error.message
          })));
        }
      }
    );
    
    await Promise.all(batchPromises);
    
    // Record batch performance metrics
    this.connectionMetrics.recordBatchOperation(
      userId,
      subscriptionBatch.length,
      results.successful.length,
      results.failed.length
    );
    
    return results;
  }
  
  // Connection health monitoring and optimization
  async monitorConnectionHealth(): Promise<ConnectionHealthReport> {
    const healthReport: ConnectionHealthReport = {
      totalConnections: this.connectionPool.size,
      healthyConnections: 0,
      unhealthyConnections: 0,
      connectionsByUser: new Map(),
      performanceMetrics: {
        averageLatency: 0,
        messagesThroughput: 0,
        errorRate: 0
      }
    };
    
    // Check health of all connections
    const healthChecks = Array.from(this.connectionPool.entries()).map(
      async ([key, connection]) => {
        const isHealthy = await this.checkConnectionHealth(connection);
        
        if (isHealthy) {
          healthReport.healthyConnections++;
        } else {
          healthReport.unhealthyConnections++;
          // Schedule unhealthy connection for cleanup
          await this.scheduleConnectionCleanup(key, connection);
        }
        
        // Track connections by user
        const userId = connection.userId;
        const userConnections = healthReport.connectionsByUser.get(userId) || 0;
        healthReport.connectionsByUser.set(userId, userConnections + 1);
      }
    );
    
    await Promise.all(healthChecks);
    
    // Calculate performance metrics
    healthReport.performanceMetrics = await this.calculatePerformanceMetrics();
    
    return healthReport;
  }
  
  // Auto-scaling for peak wedding season loads
  async scaleForPeakLoad(
    expectedConnections: number,
    peakDuration: number
  ): Promise<ScalingResult> {
    const currentCapacity = this.getCurrentCapacity();
    const requiredCapacity = Math.ceil(expectedConnections * 1.2); // 20% buffer
    
    if (requiredCapacity <= currentCapacity) {
      return {
        action: 'no_scaling_needed',
        currentCapacity,
        requiredCapacity,
        scalingActions: []
      };
    }
    
    const scalingActions: ScalingAction[] = [];
    
    // Increase connection pool limits
    const newPoolSize = Math.min(requiredCapacity, 1000); // Maximum 1000 connections
    scalingActions.push({
      type: 'increase_pool_size',
      from: currentCapacity,
      to: newPoolSize,
      estimatedDuration: 30 // 30 seconds
    });
    
    // Pre-warm connection pools
    scalingActions.push({
      type: 'prewarm_connections',
      target: Math.floor(newPoolSize * 0.3), // Pre-warm 30%
      estimatedDuration: 60 // 1 minute
    });
    
    // Enable aggressive connection cleanup
    scalingActions.push({
      type: 'enable_aggressive_cleanup',
      cleanupInterval: 30, // 30 seconds
      estimatedDuration: peakDuration
    });
    
    // Execute scaling actions
    await this.executeScalingActions(scalingActions);
    
    return {
      action: 'scaled_up',
      currentCapacity: newPoolSize,
      requiredCapacity,
      scalingActions
    };
  }
  
  // Wedding season optimization patterns
  async optimizeForWeddingSeason(): Promise<void> {
    // Enable wedding season optimizations
    await this.enableWeddingSeasonMode();
    
    // Pre-warm connections for high-traffic suppliers
    await this.prewarmHighTrafficSupplierConnections();
    
    // Optimize subscription patterns for wedding workflows
    await this.optimizeWeddingWorkflowSubscriptions();
    
    // Enable aggressive caching for wedding data
    await this.enableWeddingDataCaching();
  }
  
  // Performance monitoring and metrics
  async getRealtimePerformanceMetrics(): Promise<RealtimePerformanceMetrics> {
    return {
      connectionMetrics: {
        totalConnections: this.connectionPool.size,
        connectionsPerSecond: await this.connectionMetrics.getConnectionRate(),
        averageConnectionLatency: await this.connectionMetrics.getAverageLatency(),
        connectionReusageRate: await this.connectionMetrics.getReusageRate()
      },
      subscriptionMetrics: {
        totalSubscriptions: await this.getTotalSubscriptions(),
        subscriptionsPerConnection: await this.getAverageSubscriptionsPerConnection(),
        subscriptionUpdateRate: await this.connectionMetrics.getSubscriptionUpdateRate()
      },
      performanceMetrics: {
        averageMessageLatency: await this.connectionMetrics.getMessageLatency(),
        messagesThroughput: await this.connectionMetrics.getMessageThroughput(),
        errorRate: await this.connectionMetrics.getErrorRate()
      },
      resourceMetrics: {
        memoryUsage: process.memoryUsage(),
        cpuUsage: await this.getCPUUsage(),
        networkUtilization: await this.getNetworkUtilization()
      }
    };
  }
  
  // Connection cleanup and resource management
  private startConnectionCleanup(): void {
    this.cleanupInterval = setInterval(() => {
      this.cleanupInactiveConnections();
    }, 30000); // Every 30 seconds
  }
  
  private async cleanupInactiveConnections(): Promise<void> {
    const inactiveThreshold = Date.now() - (5 * 60 * 1000); // 5 minutes
    const connectionsToCleanup: string[] = [];
    
    for (const [key, connection] of this.connectionPool.entries()) {
      if (connection.lastActivity < inactiveThreshold || !connection.isHealthy) {
        connectionsToCleanup.push(key);
      }
    }
    
    // Cleanup inactive connections
    await Promise.all(
      connectionsToCleanup.map(key => this.cleanupConnection(key))
    );
    
    if (connectionsToCleanup.length > 0) {
      console.log(`Cleaned up ${connectionsToCleanup.length} inactive connections`);
    }
  }
  
  private async cleanupConnection(connectionKey: string): Promise<void> {
    const connection = this.connectionPool.get(connectionKey);
    if (connection) {
      await connection.disconnect();
      this.connectionPool.delete(connectionKey);
      this.connectionMetrics.recordConnectionCleanup(connectionKey);
    }
  }
}
```

2. **Realtime Cache Manager:**
```typescript
// Location: $WS_ROOT/wedsync/src/lib/performance/realtime-cache-manager.ts
export class RealtimeCacheManager {
  private redis: Redis;
  private localCache: Map<string, CacheEntry> = new Map();
  private cacheHitRatio: CacheHitTracker;
  
  constructor(redisConfig: RedisConfig) {
    this.redis = new Redis(redisConfig);
    this.cacheHitRatio = new CacheHitTracker();
    this.startCacheMaintenanceScheduler();
  }
  
  // Subscription state caching for performance
  async cacheSubscriptionState(
    userId: string,
    subscriptionState: SubscriptionState
  ): Promise<void> {
    const cacheKey = `subscription:${userId}`;
    const cacheValue = {
      ...subscriptionState,
      cachedAt: Date.now(),
      ttl: 5 * 60 * 1000 // 5 minutes TTL
    };
    
    // Store in both Redis and local cache for optimal performance
    await Promise.all([
      this.redis.setex(cacheKey, 300, JSON.stringify(cacheValue)), // 5 minutes
      this.setLocalCache(cacheKey, cacheValue)
    ]);
    
    this.cacheHitRatio.recordCacheWrite(cacheKey);
  }
  
  async getCachedSubscriptionState(
    userId: string
  ): Promise<SubscriptionState | null> {
    const cacheKey = `subscription:${userId}`;
    
    // Try local cache first for best performance
    const localCached = this.getLocalCache(cacheKey);
    if (localCached && !this.isCacheExpired(localCached)) {
      this.cacheHitRatio.recordCacheHit(cacheKey, 'local');
      return localCached.data;
    }
    
    // Try Redis cache
    try {
      const redisCached = await this.redis.get(cacheKey);
      if (redisCached) {
        const parsedCache = JSON.parse(redisCached);
        
        // Update local cache
        this.setLocalCache(cacheKey, parsedCache);
        
        this.cacheHitRatio.recordCacheHit(cacheKey, 'redis');
        return parsedCache;
      }
    } catch (error) {
      console.error('Redis cache error:', error);
    }
    
    this.cacheHitRatio.recordCacheMiss(cacheKey);
    return null;
  }
  
  // User data caching for realtime efficiency
  async cacheUserRealtimeData(
    userId: string,
    userData: UserRealtimeData
  ): Promise<void> {
    const cacheKey = `realtime_user:${userId}`;
    const cacheValue = {
      ...userData,
      cachedAt: Date.now(),
      ttl: 10 * 60 * 1000 // 10 minutes TTL for user data
    };
    
    await this.redis.setex(cacheKey, 600, JSON.stringify(cacheValue));
    this.setLocalCache(cacheKey, cacheValue);
  }
  
  async getCachedUserRealtimeData(
    userId: string
  ): Promise<UserRealtimeData | null> {
    return this.getCachedData(`realtime_user:${userId}`);
  }
  
  // Wedding data caching for coordination efficiency
  async cacheWeddingRealtimeData(
    weddingId: string,
    weddingData: WeddingRealtimeData
  ): Promise<void> {
    const cacheKey = `wedding_realtime:${weddingId}`;
    const cacheValue = {
      ...weddingData,
      cachedAt: Date.now(),
      ttl: 2 * 60 * 1000 // 2 minutes TTL for wedding data (more frequent updates)
    };
    
    await this.redis.setex(cacheKey, 120, JSON.stringify(cacheValue));
    this.setLocalCache(cacheKey, cacheValue);
  }
  
  async getCachedWeddingRealtimeData(
    weddingId: string
  ): Promise<WeddingRealtimeData | null> {
    return this.getCachedData(`wedding_realtime:${weddingId}`);
  }
  
  // Connection metadata caching
  async cacheConnectionMetadata(
    connectionId: string,
    metadata: ConnectionMetadata
  ): Promise<void> {
    const cacheKey = `connection:${connectionId}`;
    const cacheValue = {
      ...metadata,
      cachedAt: Date.now(),
      ttl: 30 * 60 * 1000 // 30 minutes TTL for connection metadata
    };
    
    await this.redis.setex(cacheKey, 1800, JSON.stringify(cacheValue));
    this.setLocalCache(cacheKey, cacheValue);
  }
  
  // Cache optimization for peak loads
  async optimizeCacheForPeakLoad(): Promise<CacheOptimizationResult> {
    const optimizationResults: CacheOptimizationResult = {
      actions: [],
      performanceGains: {},
      errors: []
    };
    
    try {
      // Increase local cache size for better hit ratio
      this.expandLocalCacheCapacity(1000); // Increase to 1000 entries
      optimizationResults.actions.push('expanded_local_cache');
      
      // Pre-warm cache with frequently accessed data
      await this.prewarmFrequentlyAccessedData();
      optimizationResults.actions.push('prewarmed_cache');
      
      // Optimize Redis connection pool
      await this.optimizeRedisConnectionPool();
      optimizationResults.actions.push('optimized_redis_pool');
      
      // Enable aggressive cache compression
      this.enableCacheCompression();
      optimizationResults.actions.push('enabled_compression');
      
      // Calculate performance gains
      optimizationResults.performanceGains = await this.calculateOptimizationGains();
      
    } catch (error) {
      optimizationResults.errors.push(error.message);
    }
    
    return optimizationResults;
  }
  
  // Cache performance monitoring
  async getCachePerformanceMetrics(): Promise<CachePerformanceMetrics> {
    const hitRatioStats = await this.cacheHitRatio.getStats();
    const redisInfo = await this.redis.info('memory');
    
    return {
      hitRatio: {
        overall: hitRatioStats.overall,
        local: hitRatioStats.local,
        redis: hitRatioStats.redis
      },
      performance: {
        averageReadLatency: hitRatioStats.averageReadLatency,
        averageWriteLatency: hitRatioStats.averageWriteLatency,
        operationsPerSecond: hitRatioStats.operationsPerSecond
      },
      memory: {
        localCacheSize: this.localCache.size,
        localCacheMemory: this.calculateLocalCacheMemoryUsage(),
        redisMemoryUsage: this.parseRedisMemoryInfo(redisInfo)
      },
      optimization: {
        compressionRatio: await this.getCacheCompressionRatio(),
        evictionRate: await this.getCacheEvictionRate(),
        preloadEffectiveness: await this.getPreloadEffectiveness()
      }
    };
  }
  
  // Wedding season cache warming
  async warmCacheForWeddingSeason(
    activeSuppliers: string[],
    upcomingWeddings: string[]
  ): Promise<void> {
    console.log('Warming cache for wedding season...');
    
    // Pre-load active supplier subscription states
    const supplierPromises = activeSuppliers.map(async supplierId => {
      try {
        // Load supplier realtime data
        const supplierData = await this.loadSupplierRealtimeData(supplierId);
        await this.cacheUserRealtimeData(supplierId, supplierData);
        
        // Load supplier subscription preferences
        const subscriptionState = await this.loadSupplierSubscriptionState(supplierId);
        await this.cacheSubscriptionState(supplierId, subscriptionState);
        
      } catch (error) {
        console.error(`Failed to warm cache for supplier ${supplierId}:`, error);
      }
    });
    
    // Pre-load upcoming wedding data
    const weddingPromises = upcomingWeddings.map(async weddingId => {
      try {
        const weddingData = await this.loadWeddingRealtimeData(weddingId);
        await this.cacheWeddingRealtimeData(weddingId, weddingData);
      } catch (error) {
        console.error(`Failed to warm cache for wedding ${weddingId}:`, error);
      }
    });
    
    // Execute warming in parallel with controlled concurrency
    const batchSize = 10;
    const allPromises = [...supplierPromises, ...weddingPromises];
    
    for (let i = 0; i < allPromises.length; i += batchSize) {
      const batch = allPromises.slice(i, i + batchSize);
      await Promise.all(batch);
      
      // Brief pause between batches to prevent overwhelming the system
      if (i + batchSize < allPromises.length) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }
    
    console.log(`Cache warmed for ${activeSuppliers.length} suppliers and ${upcomingWeddings.length} weddings`);
  }
  
  // Cache cleanup and maintenance
  private startCacheMaintenanceScheduler(): void {
    // Clean expired local cache entries every 2 minutes
    setInterval(() => {
      this.cleanupExpiredLocalCache();
    }, 2 * 60 * 1000);
    
    // Optimize cache structure every 10 minutes
    setInterval(() => {
      this.optimizeCacheStructure();
    }, 10 * 60 * 1000);
  }
  
  private cleanupExpiredLocalCache(): void {
    const now = Date.now();
    const expiredKeys: string[] = [];
    
    for (const [key, entry] of this.localCache.entries()) {
      if (this.isCacheExpired(entry, now)) {
        expiredKeys.push(key);
      }
    }
    
    expiredKeys.forEach(key => this.localCache.delete(key));
    
    if (expiredKeys.length > 0) {
      console.log(`Cleaned up ${expiredKeys.length} expired cache entries`);
    }
  }
}
```

## üìã TECHNICAL SPECIFICATION FROM WS-202

**Performance Requirements:**
- Sub-500ms realtime update latency during peak loads
- Support for 200+ simultaneous connections per supplier
- Connection pooling optimization for resource efficiency
- Auto-scaling for wedding season traffic spikes (10x normal load)
- Cache hit ratio optimization (>90%) for subscription state

**Infrastructure Requirements:**
- Redis caching layer for subscription state and user data
- Connection pool management with automated cleanup
- Auto-scaling triggers based on connection count and latency
- Performance monitoring with real-time alerting
- Memory optimization for long-running realtime connections

## üéØ SPECIFIC DELIVERABLES FOR ROUND 1

### Core Performance Implementation:
- [ ] RealtimeConnectionOptimizer with connection pooling and reuse
- [ ] RealtimeCacheManager with Redis and local cache layers
- [ ] RealtimeScalingManager with auto-scaling capabilities
- [ ] Performance monitoring dashboard with realtime metrics
- [ ] Wedding season optimization patterns and cache warming

### Connection Optimization:
- [ ] Connection pool management with health monitoring
- [ ] Batch subscription processing for efficiency
- [ ] Connection cleanup automation for resource management
- [ ] Connection reuse optimization for reduced overhead
- [ ] Connection health monitoring with automatic recovery

### Caching Strategy:
- [ ] Multi-layer caching (local + Redis) for optimal performance
- [ ] Subscription state caching with appropriate TTLs
- [ ] User and wedding data caching for realtime access
- [ ] Cache warming strategies for wedding season
- [ ] Cache performance monitoring and optimization

### Infrastructure Scaling:
- [ ] Auto-scaling policies for peak traffic handling
- [ ] Performance-based scaling triggers
- [ ] Resource monitoring and alerting systems
- [ ] Connection capacity planning and optimization
- [ ] Wedding season scaling preparation and testing

## üíæ WHERE TO SAVE YOUR WORK
- Performance Systems: $WS_ROOT/wedsync/src/lib/performance/
- Infrastructure: $WS_ROOT/wedsync/src/lib/infrastructure/
- Cache Management: $WS_ROOT/wedsync/src/lib/cache/
- Monitoring: $WS_ROOT/wedsync/src/lib/monitoring/
- Types: $WS_ROOT/wedsync/src/types/realtime-performance.ts
- Tests: $WS_ROOT/wedsync/__tests__/performance/realtime/
- Reports: $WS_ROOT/WORKFLOW-V2-DRAFT/INBOX/senior-dev/WS-202-team-d-round-1-complete.md

## üèÅ COMPLETION CHECKLIST
- [ ] RealtimeConnectionOptimizer implemented with connection pooling
- [ ] RealtimeCacheManager with multi-layer caching strategy
- [ ] RealtimeScalingManager with auto-scaling policies
- [ ] Performance monitoring system with realtime metrics
- [ ] Sub-500ms update latency achieved under load
- [ ] 200+ connection support per supplier implemented
- [ ] >90% cache hit ratio for subscription state achieved
- [ ] Auto-scaling triggers configured and tested
- [ ] Wedding season optimization patterns implemented
- [ ] Connection cleanup automation functional
- [ ] TypeScript compilation successful
- [ ] All performance tests passing with benchmarks
- [ ] Evidence package prepared with performance metrics
- [ ] Senior dev review prompt created

---

**EXECUTE IMMEDIATELY - This is a comprehensive prompt with all requirements for realtime performance optimization!**